{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderPidodnya/MaisRecognition/blob/main/Mais_Training_and_Detection_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only for colab\n",
        "!pip uninstall tensorflow -q\n",
        "#!pip install tensorflow==2.7.0\n",
        "!pip install tensorflow==2.8 -q\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "#restart kernel"
      ],
      "metadata": {
        "id": "KmjTju7b2fFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b9d032-2371-473d-90eb-d7102cdb636d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed (y/n)? y\n",
            "y\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 37.6 MB/s \n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 7s (61.8 MB/s)\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155617 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "146BB11JpfDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d5f6ae-c4ed-46d3-b1f1-34330715aca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.1\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_mobilenet' \n",
        "#PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "#PRETRAINED_MODEL_NAME = 'ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz'\n",
        "#PRETRAINED_MODEL_NAME = 'efficientdet_d6_coco17_tpu-32'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_8tIWtKd0-F",
        "outputId": "3c625b37-1748-45d3-cd04-f961425ccd27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.21.6', '2.8.0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "DwPu62ZDc_ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TE6vguv1vcW",
        "outputId": "f190784e-28ac-49fb-b9ea-ea62d59240f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LABELMAP': 'Tensorflow/workspace/annotations/label_map.pbtxt',\n",
              " 'PIPELINE_CONFIG': 'Tensorflow/workspace/models/my_mobilenet/pipeline.config',\n",
              " 'TF_RECORD_SCRIPT': 'Tensorflow/scripts/generate_tfrecord.py'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRIABN0_Xhfc"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bed80d6-bdd7-4018-decd-44e0fb0bb6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 74707, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 74707 (delta 102), reused 151 (delta 79), pack-reused 74512\u001b[K\n",
            "Receiving objects: 100% (74707/74707), 580.41 MiB | 17.30 MiB/s, done.\n",
            "Resolving deltas: 100% (52996/52996), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0cadeb-ccdc-4215-cf41-6c778e166983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.39.0-cp37-cp37m-manylinux2010_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 88 kB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.2 kB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 54.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 60.7 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694695 sha256=dae32b0122a7e0f87050cd3ac4bb667dc9a3ff14d0483989df49a133bea78e7b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ymdnn2eh/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=0bbeb9fc92d687b76ff8f82e41dacf85d7255057682550ce15655322d8ba36b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=1d15d9bdae72eb63f1139c879d04d7fa69c97d3f0e61a9d64701b6fb8cb0f3eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=72c0d4ebd5ed643dd7769b86ee99ea9d608ece2d2cacf330b4dd557b9378115a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=55a01e3b78cca13ceb9de17ffbe980836e1beb25d9330dfe9b826bd0ccd011fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.2 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.3 portalocker-2.4.0 proto-plus-1.20.6 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.0 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AsxYBmeFYRzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceb4195-6eea-4c6b-d4d5-3b985e3aa8c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyDGNiKUXhfg",
        "outputId": "1714dc55-93a6-4814-cca6-53019b22eea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-06-24 18:39:23.814948: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0624 18:39:24.075839 140413450200960 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.67s\n",
            "I0624 18:39:24.487368 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "I0624 18:39:25.058763 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "I0624 18:39:25.348471 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "I0624 18:39:25.613681 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.13s\n",
            "I0624 18:39:27.746114 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0624 18:39:27.747106 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0624 18:39:27.771192 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0624 18:39:27.787100 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0624 18:39:27.801881 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "I0624 18:39:27.905455 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0624 18:39:27.998696 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0624 18:39:28.094038 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "I0624 18:39:28.190659 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0624 18:39:28.289904 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0624 18:39:28.319995 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0624 18:39:28.512298 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0624 18:39:28.512462 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0624 18:39:28.512537 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0624 18:39:28.514830 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:28.533102 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:28.533249 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:28.602330 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:28.602505 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:28.782766 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:28.782979 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:28.966632 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:28.966841 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:29.236128 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:29.236324 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:29.485214 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:29.485407 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:29.861942 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:29.862168 140413450200960 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0624 18:39:29.956846 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0624 18:39:29.996822 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:30.247163 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0624 18:39:30.247375 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0624 18:39:30.247462 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0624 18:39:30.249339 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:30.270002 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:30.270237 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:30.419929 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:30.420140 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:30.661950 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:30.662116 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:30.913701 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:30.913905 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:31.241917 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:31.242106 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:31.580046 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:31.580236 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:31.981278 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:31.981448 140413450200960 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0624 18:39:32.132890 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0624 18:39:32.164004 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:32.228915 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0624 18:39:32.229134 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0624 18:39:32.229220 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0624 18:39:32.231701 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:32.248402 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:32.248544 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:32.379191 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:32.379358 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:32.618590 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:32.618758 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:32.863414 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:32.863576 140413450200960 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0624 18:39:33.186033 140413450200960 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0624 18:39:33.186204 140413450200960 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0624 18:39:33.514497 140413450200960 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0624 18:39:33.514669 140413450200960 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0624 18:39:33.928471 140413450200960 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0624 18:39:33.928666 140413450200960 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0624 18:39:34.087895 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0624 18:39:34.117861 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:34.180376 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0624 18:39:34.180539 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0624 18:39:34.180616 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0624 18:39:34.182273 140413450200960 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0624 18:39:34.198441 140413450200960 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0624 18:39:34.198564 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:34.319888 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:34.320075 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:34.554149 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:34.554315 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:34.784173 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:34.784339 140413450200960 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0624 18:39:35.184455 140413450200960 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0624 18:39:35.184628 140413450200960 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0624 18:39:35.768588 140413450200960 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0624 18:39:35.768757 140413450200960 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0624 18:39:36.262497 140413450200960 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0624 18:39:36.262683 140413450200960 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0624 18:39:36.427155 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0624 18:39:36.456774 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:36.524399 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0624 18:39:36.524572 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0624 18:39:36.524662 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0624 18:39:36.526358 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:36.548913 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:36.549085 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:36.685201 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:36.685396 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:37.021621 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:37.021805 140413450200960 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0624 18:39:37.345455 140413450200960 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0624 18:39:37.345642 140413450200960 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0624 18:39:37.852180 140413450200960 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0624 18:39:37.852345 140413450200960 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0624 18:39:38.367744 140413450200960 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0624 18:39:38.367938 140413450200960 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0624 18:39:39.040249 140413450200960 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0624 18:39:39.040425 140413450200960 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0624 18:39:39.200330 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0624 18:39:39.230144 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:39.315209 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0624 18:39:39.315360 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0624 18:39:39.315432 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0624 18:39:39.316946 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:39.333431 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:39.333545 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:39.525480 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:39.525651 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:39.915038 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:39.915217 140413450200960 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0624 18:39:40.314213 140413450200960 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0624 18:39:40.314378 140413450200960 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0624 18:39:40.873874 140413450200960 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0624 18:39:40.874053 140413450200960 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0624 18:39:41.646679 140413450200960 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0624 18:39:41.646853 140413450200960 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0624 18:39:42.367084 140413450200960 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0624 18:39:42.367267 140413450200960 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0624 18:39:42.602052 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0624 18:39:42.630858 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:42.715494 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0624 18:39:42.715651 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0624 18:39:42.715740 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0624 18:39:42.717359 140413450200960 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0624 18:39:42.734271 140413450200960 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0624 18:39:42.734390 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:42.922067 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:42.922235 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:43.407027 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:43.407192 140413450200960 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0624 18:39:43.880269 140413450200960 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0624 18:39:43.880439 140413450200960 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0624 18:39:44.528771 140413450200960 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0624 18:39:44.528967 140413450200960 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0624 18:39:45.161717 140413450200960 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0624 18:39:45.161921 140413450200960 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0624 18:39:46.061461 140413450200960 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0624 18:39:46.061674 140413450200960 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0624 18:39:46.302970 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0624 18:39:46.333019 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:46.430605 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0624 18:39:46.430757 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0624 18:39:46.430827 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0624 18:39:46.432527 140413450200960 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0624 18:39:46.447967 140413450200960 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0624 18:39:46.448073 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:46.712241 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:46.712412 140413450200960 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0624 18:39:47.510081 140413450200960 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0624 18:39:47.510275 140413450200960 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0624 18:39:48.076568 140413450200960 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0624 18:39:48.076750 140413450200960 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0624 18:39:48.895634 140413450200960 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0624 18:39:48.895803 140413450200960 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0624 18:39:49.678145 140413450200960 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0624 18:39:49.678318 140413450200960 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0624 18:39:50.717824 140413450200960 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0624 18:39:50.718010 140413450200960 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0624 18:39:51.035020 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0624 18:39:51.077247 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.89s\n",
            "I0624 18:39:51.209360 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.89s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0624 18:39:51.215465 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0624 18:39:51.217306 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0624 18:39:51.217834 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0624 18:39:51.219449 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0624 18:39:51.220887 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0624 18:39:51.221374 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0624 18:39:51.222406 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.403s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -q '/content/drive/MyDrive/diploma/base/stampsignatures.zip' -d /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "SAV0XKfee_Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/collectedimages.zip' -d /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "_ZUAY7nUhWyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Tensorflow/workspace/images\n",
        "!mkdir  /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "yu536zT3FMAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zOWvs1g-Xhfh",
        "outputId": "a973095c-782a-40fe-9acd-4efa11d250f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.24.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.20.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.19.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip install tensorflow-gpu --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zJrwUEysXhfi",
        "outputId": "951d7309-02ce-4928-8ae1-4bc959ed0a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: protobuf 3.15.7\n",
            "Uninstalling protobuf-3.15.7:\n",
            "  Successfully uninstalled protobuf-3.15.7\n",
            "Found existing installation: matplotlib 3.4.1\n",
            "Uninstalling matplotlib-3.4.1:\n",
            "  Successfully uninstalled matplotlib-3.4.1\n",
            "Collecting protobuf"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.28.0 requires crcmod<2.0,>=1.7, which is not installed.\n",
            "apache-beam 2.28.0 requires dill<0.3.2,>=0.3.1.1, which is not installed.\n",
            "apache-beam 2.28.0 requires fastavro<2,>=0.21.4, which is not installed.\n",
            "apache-beam 2.28.0 requires future<1.0.0,>=0.18.2, which is not installed.\n",
            "apache-beam 2.28.0 requires grpcio<2,>=1.29.0, which is not installed.\n",
            "apache-beam 2.28.0 requires hdfs<3.0.0,>=2.1.0, which is not installed.\n",
            "apache-beam 2.28.0 requires httplib2<0.18.0,>=0.8, which is not installed.\n",
            "apache-beam 2.28.0 requires mock<3.0.0,>=1.0.1, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires astunparse~=1.6.3, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires flatbuffers~=1.12.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires gast==0.4.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires google-pasta~=0.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires grpcio~=1.34.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires h5py~=3.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-nightly~=2.5.0.dev, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-preprocessing~=1.1.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires opt-einsum~=3.3.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tensorboard~=2.4, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires termcolor~=1.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tf-estimator-nightly==2.5.0.dev2021032501, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires wrapt~=1.12.1, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires attrs>=18.1.0, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires dill, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires future, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires importlib-resources, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires promise, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tensorflow-metadata, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires termcolor, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tqdm, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-api-core[grpc]<2.0.0dev,>=1.23.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-cloud-core<2.0dev,>=1.4.1, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-resumable-media<2.0dev,>=0.6.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires packaging>=14.3, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires proto-plus>=1.10.0, which is not installed.\n",
            "apache-beam 2.28.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you have avro-python3 1.10.2 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading protobuf-3.15.7-cp37-cp37m-win_amd64.whl (904 kB)\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached matplotlib-3.2.0-cp37-cp37m-win_amd64.whl (9.2 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\cycler-0.10.0-py3.7.egg (from matplotlib==3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\kiwisolver-1.3.1-py3.7-win-amd64.egg (from matplotlib==3.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\pyparsing-3.0.0b2-py3.7.egg (from matplotlib==3.2) (3.0.0b2)\n",
            "Requirement already satisfied: numpy>=1.11 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: six in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from cycler>=0.10->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.15.7\n"
          ]
        }
      ],
      "source": [
        "#!pip uninstall protobuf matplotlib -y\n",
        "#!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3WUN9wGXhfi"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list  #curr"
      ],
      "metadata": {
        "id": "ofaQDPMdfKK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fQMXEUHDXhfj"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "1afbe6c7-c8ad-4d24-fe8b-496d994eee88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 18:28:18--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.24.128, 2404:6800:4003:c00::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.24.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  50.1MB/s    in 0.4s    \n",
            "\n",
            "2022-06-27 18:28:20 (50.1 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'thumbsup', 'id':1},\n",
        "          {'name':'thumbsdown', 'id':2}, \n",
        "          {'name':'thankyou', 'id':3},\n",
        "          {'name':'fist', 'id':4},\n",
        "          {'name':'united', 'id':5},\n",
        "          {'name':'victory', 'id':6}]\n",
        "          \n",
        "labels = [{'name' : 'mais', 'id':1},\n",
        "          {'name' : 'dill', 'id':2},\n",
        "          {'name' : 'buckwheat', 'id':3},\n",
        "          {'name' : 'other', 'id':4}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item {\\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KWpb_BVUpfDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bedd84d-8919-42b9-d3c2-196ee61d1974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resources = '/content/resources'\n",
        "if not os.path.exists(resources):\n",
        "  !mkdir {resources}\n",
        "!git clone https://github.com/AlexanderPidodnya/MaisRecognition {resources}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVl2vyTcITYT",
        "outputId": "4a5b09e3-3189-45cc-a3e5-3469adef240c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/resources'...\n",
            "remote: Enumerating objects: 1949, done.\u001b[K\n",
            "remote: Counting objects: 100% (1879/1879), done.\u001b[K\n",
            "remote: Compressing objects: 100% (456/456), done.\u001b[K\n",
            "remote: Total 1949 (delta 1461), reused 1826 (delta 1411), pack-reused 70\u001b[K\n",
            "Receiving objects: 100% (1949/1949), 109.92 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (1482/1482), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coping from resources\n",
        "import glob, shutil\n",
        "onColab = os.name =='posix' \n",
        "if not onColab:\n",
        "\n",
        "  res_img = r'C:\\Users\\AdminAsus\\PycharmProjects\\MaisRecognition\\resources'\n",
        "  train_path = os.path.join(paths['IMAGE_PATH'], 'train')\n",
        "  test_path = os.path.join(paths['IMAGE_PATH'], 'test')\n",
        "  if not os.path.exists(train_path):\n",
        "      !mkdir {train_path}\n",
        "  if not os.path.exists(test_path):\n",
        "      !mkdir {test_path}\n",
        "if onColab:\n",
        "  res_img = r'/content/resources/SlicedImages_2'\n",
        "  train_path = os.path.join(paths['IMAGE_PATH'], 'train')\n",
        "  test_path = os.path.join(paths['IMAGE_PATH'], 'test')\n",
        "  if not os.path.exists(train_path):\n",
        "      !mkdir {train_path}\n",
        "  if not os.path.exists(test_path):\n",
        "      !mkdir {test_path}\n",
        "\n",
        "imgs = []\n",
        "rr = '.jpg'\n",
        "for img in os.listdir(res_img):\n",
        "  if rr in img.lower():\n",
        "    imgs.append(img[:-4])\n",
        "tr_k = len(imgs) * 0.8\n",
        "for i, img in enumerate(imgs):\n",
        "  fList = glob.glob(os.path.join(res_img, img+'*.*'))\n",
        "  \n",
        "  for f in fList:\n",
        "    #print(f)\n",
        "    if i<tr_k:\n",
        "      if onColab:\n",
        "        !cp {f} {train_path} \n",
        "      else:\n",
        "        !copy {f} {train_path} \n",
        "    else:\n",
        "      if onColab:\n",
        "        !cp {f} {test_path}        \n",
        "      else:\n",
        "        !copy {f} {test_path}        \n",
        "# may use a directive like !copy"
      ],
      "metadata": {
        "id": "clnGmzluIam0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "7e4a948e-7cfd-4279-bda5-394e1617b335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iySTyyTIkzgf",
        "outputId": "210fd1c5-af9e-455a-cb2f-c242421d76f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "e79575c0-ceda-458b-8f6b-31e036c3f678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7OjJvh4l3Yx",
        "outputId": "fdc8cbc0-284f-4472-b7cd-214311591e5c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 4\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 640\n",
              "        width: 640\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "46098173-a51f-4673-f7d6-0b8750cb438b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_mobilenet --pipeline_config_path=Tensorflow/workspace/models/my_mobilenet/pipeline.config --num_train_steps=5000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6KpyP0zi2eK",
        "outputId": "63d55b5a-d125-464e-e623-c2bc63615e72"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i3ZsJR-qpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477ea06c-07f6-47ed-9526-858d6e9a3a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-27 18:36:27.194552: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0627 18:36:27.201632 139980769736576 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0627 18:36:27.205224 139980769736576 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0627 18:36:27.205405 139980769736576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0627 18:36:27.368674 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0627 18:36:27.375394 139980769736576 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0627 18:36:27.375727 139980769736576 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0627 18:36:27.375900 139980769736576 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0627 18:36:27.376041 139980769736576 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0627 18:36:27.379461 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0627 18:36:27.401817 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0627 18:36:39.999800 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0627 18:36:44.363880 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 18:36:45.954752 139980769736576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.980081 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.981391 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.983741 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.984662 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.986689 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.987588 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.989593 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.990519 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.992554 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 18:37:13.993449 139980769736576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0627 18:37:14.607206 139975885240064 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.662s\n",
            "I0627 18:38:20.419041 139980769736576 model_lib_v2.py:707] Step 100 per-step time 0.662s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31688008,\n",
            " 'Loss/localization_loss': 0.16528241,\n",
            " 'Loss/regularization_loss': 0.15162325,\n",
            " 'Loss/total_loss': 0.6337857,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0627 18:38:20.419441 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.31688008,\n",
            " 'Loss/localization_loss': 0.16528241,\n",
            " 'Loss/regularization_loss': 0.15162325,\n",
            " 'Loss/total_loss': 0.6337857,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.309s\n",
            "I0627 18:38:51.333142 139980769736576 model_lib_v2.py:707] Step 200 per-step time 0.309s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20124227,\n",
            " 'Loss/localization_loss': 0.16555291,\n",
            " 'Loss/regularization_loss': 0.15137938,\n",
            " 'Loss/total_loss': 0.5181745,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0627 18:38:51.333500 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.20124227,\n",
            " 'Loss/localization_loss': 0.16555291,\n",
            " 'Loss/regularization_loss': 0.15137938,\n",
            " 'Loss/total_loss': 0.5181745,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.311s\n",
            "I0627 18:39:22.478356 139980769736576 model_lib_v2.py:707] Step 300 per-step time 0.311s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19128332,\n",
            " 'Loss/localization_loss': 0.06587737,\n",
            " 'Loss/regularization_loss': 0.15104088,\n",
            " 'Loss/total_loss': 0.40820158,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0627 18:39:22.478651 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.19128332,\n",
            " 'Loss/localization_loss': 0.06587737,\n",
            " 'Loss/regularization_loss': 0.15104088,\n",
            " 'Loss/total_loss': 0.40820158,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.315s\n",
            "I0627 18:39:53.996077 139980769736576 model_lib_v2.py:707] Step 400 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1629454,\n",
            " 'Loss/localization_loss': 0.058359385,\n",
            " 'Loss/regularization_loss': 0.15066165,\n",
            " 'Loss/total_loss': 0.37196642,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0627 18:39:53.996450 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.1629454,\n",
            " 'Loss/localization_loss': 0.058359385,\n",
            " 'Loss/regularization_loss': 0.15066165,\n",
            " 'Loss/total_loss': 0.37196642,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.311s\n",
            "I0627 18:40:25.084075 139980769736576 model_lib_v2.py:707] Step 500 per-step time 0.311s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17049806,\n",
            " 'Loss/localization_loss': 0.058314588,\n",
            " 'Loss/regularization_loss': 0.15026775,\n",
            " 'Loss/total_loss': 0.3790804,\n",
            " 'learning_rate': 0.053333}\n",
            "I0627 18:40:25.084389 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.17049806,\n",
            " 'Loss/localization_loss': 0.058314588,\n",
            " 'Loss/regularization_loss': 0.15026775,\n",
            " 'Loss/total_loss': 0.3790804,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.314s\n",
            "I0627 18:40:56.437519 139980769736576 model_lib_v2.py:707] Step 600 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.113899395,\n",
            " 'Loss/localization_loss': 0.05311021,\n",
            " 'Loss/regularization_loss': 0.1497725,\n",
            " 'Loss/total_loss': 0.31678212,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0627 18:40:56.437811 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.113899395,\n",
            " 'Loss/localization_loss': 0.05311021,\n",
            " 'Loss/regularization_loss': 0.1497725,\n",
            " 'Loss/total_loss': 0.31678212,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.311s\n",
            "I0627 18:41:27.580404 139980769736576 model_lib_v2.py:707] Step 700 per-step time 0.311s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13716052,\n",
            " 'Loss/localization_loss': 0.044560444,\n",
            " 'Loss/regularization_loss': 0.14922757,\n",
            " 'Loss/total_loss': 0.33094853,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0627 18:41:27.580710 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13716052,\n",
            " 'Loss/localization_loss': 0.044560444,\n",
            " 'Loss/regularization_loss': 0.14922757,\n",
            " 'Loss/total_loss': 0.33094853,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.311s\n",
            "I0627 18:41:58.673063 139980769736576 model_lib_v2.py:707] Step 800 per-step time 0.311s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12531753,\n",
            " 'Loss/localization_loss': 0.03721722,\n",
            " 'Loss/regularization_loss': 0.14867362,\n",
            " 'Loss/total_loss': 0.31120837,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0627 18:41:58.673455 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12531753,\n",
            " 'Loss/localization_loss': 0.03721722,\n",
            " 'Loss/regularization_loss': 0.14867362,\n",
            " 'Loss/total_loss': 0.31120837,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.313s\n",
            "I0627 18:42:29.933174 139980769736576 model_lib_v2.py:707] Step 900 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10465616,\n",
            " 'Loss/localization_loss': 0.043611243,\n",
            " 'Loss/regularization_loss': 0.1480868,\n",
            " 'Loss/total_loss': 0.2963542,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0627 18:42:29.933478 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.10465616,\n",
            " 'Loss/localization_loss': 0.043611243,\n",
            " 'Loss/regularization_loss': 0.1480868,\n",
            " 'Loss/total_loss': 0.2963542,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.314s\n",
            "I0627 18:43:01.317948 139980769736576 model_lib_v2.py:707] Step 1000 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12392482,\n",
            " 'Loss/localization_loss': 0.035578255,\n",
            " 'Loss/regularization_loss': 0.1474049,\n",
            " 'Loss/total_loss': 0.30690795,\n",
            " 'learning_rate': 0.08}\n",
            "I0627 18:43:01.318253 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12392482,\n",
            " 'Loss/localization_loss': 0.035578255,\n",
            " 'Loss/regularization_loss': 0.1474049,\n",
            " 'Loss/total_loss': 0.30690795,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.318s\n",
            "I0627 18:43:33.081432 139980769736576 model_lib_v2.py:707] Step 1100 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13575728,\n",
            " 'Loss/localization_loss': 0.07255973,\n",
            " 'Loss/regularization_loss': 0.14671104,\n",
            " 'Loss/total_loss': 0.35502803,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0627 18:43:33.081736 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13575728,\n",
            " 'Loss/localization_loss': 0.07255973,\n",
            " 'Loss/regularization_loss': 0.14671104,\n",
            " 'Loss/total_loss': 0.35502803,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.312s\n",
            "I0627 18:44:04.320539 139980769736576 model_lib_v2.py:707] Step 1200 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16204967,\n",
            " 'Loss/localization_loss': 0.04632221,\n",
            " 'Loss/regularization_loss': 0.1461595,\n",
            " 'Loss/total_loss': 0.35453138,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0627 18:44:04.320922 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.16204967,\n",
            " 'Loss/localization_loss': 0.04632221,\n",
            " 'Loss/regularization_loss': 0.1461595,\n",
            " 'Loss/total_loss': 0.35453138,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.313s\n",
            "I0627 18:44:35.640583 139980769736576 model_lib_v2.py:707] Step 1300 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.085159265,\n",
            " 'Loss/localization_loss': 0.04011584,\n",
            " 'Loss/regularization_loss': 0.14544094,\n",
            " 'Loss/total_loss': 0.27071604,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0627 18:44:35.640885 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.085159265,\n",
            " 'Loss/localization_loss': 0.04011584,\n",
            " 'Loss/regularization_loss': 0.14544094,\n",
            " 'Loss/total_loss': 0.27071604,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.312s\n",
            "I0627 18:45:06.888979 139980769736576 model_lib_v2.py:707] Step 1400 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08435529,\n",
            " 'Loss/localization_loss': 0.031546965,\n",
            " 'Loss/regularization_loss': 0.14471434,\n",
            " 'Loss/total_loss': 0.2606166,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0627 18:45:06.889314 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.08435529,\n",
            " 'Loss/localization_loss': 0.031546965,\n",
            " 'Loss/regularization_loss': 0.14471434,\n",
            " 'Loss/total_loss': 0.2606166,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.312s\n",
            "I0627 18:45:38.039947 139980769736576 model_lib_v2.py:707] Step 1500 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12344688,\n",
            " 'Loss/localization_loss': 0.045101583,\n",
            " 'Loss/regularization_loss': 0.14398651,\n",
            " 'Loss/total_loss': 0.312535,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0627 18:45:38.040259 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12344688,\n",
            " 'Loss/localization_loss': 0.045101583,\n",
            " 'Loss/regularization_loss': 0.14398651,\n",
            " 'Loss/total_loss': 0.312535,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.313s\n",
            "I0627 18:46:09.381164 139980769736576 model_lib_v2.py:707] Step 1600 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07642112,\n",
            " 'Loss/localization_loss': 0.012540925,\n",
            " 'Loss/regularization_loss': 0.14324003,\n",
            " 'Loss/total_loss': 0.23220208,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0627 18:46:09.381511 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07642112,\n",
            " 'Loss/localization_loss': 0.012540925,\n",
            " 'Loss/regularization_loss': 0.14324003,\n",
            " 'Loss/total_loss': 0.23220208,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.313s\n",
            "I0627 18:46:40.679165 139980769736576 model_lib_v2.py:707] Step 1700 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17182149,\n",
            " 'Loss/localization_loss': 0.047301427,\n",
            " 'Loss/regularization_loss': 0.14251833,\n",
            " 'Loss/total_loss': 0.36164123,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0627 18:46:40.679479 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.17182149,\n",
            " 'Loss/localization_loss': 0.047301427,\n",
            " 'Loss/regularization_loss': 0.14251833,\n",
            " 'Loss/total_loss': 0.36164123,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.313s\n",
            "I0627 18:47:11.981780 139980769736576 model_lib_v2.py:707] Step 1800 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12940782,\n",
            " 'Loss/localization_loss': 0.03411574,\n",
            " 'Loss/regularization_loss': 0.14177458,\n",
            " 'Loss/total_loss': 0.30529815,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0627 18:47:11.982074 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12940782,\n",
            " 'Loss/localization_loss': 0.03411574,\n",
            " 'Loss/regularization_loss': 0.14177458,\n",
            " 'Loss/total_loss': 0.30529815,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.313s\n",
            "I0627 18:47:43.256596 139980769736576 model_lib_v2.py:707] Step 1900 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09135977,\n",
            " 'Loss/localization_loss': 0.028897636,\n",
            " 'Loss/regularization_loss': 0.1410356,\n",
            " 'Loss/total_loss': 0.261293,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0627 18:47:43.256892 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.09135977,\n",
            " 'Loss/localization_loss': 0.028897636,\n",
            " 'Loss/regularization_loss': 0.1410356,\n",
            " 'Loss/total_loss': 0.261293,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.314s\n",
            "I0627 18:48:14.650630 139980769736576 model_lib_v2.py:707] Step 2000 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11458485,\n",
            " 'Loss/localization_loss': 0.030506015,\n",
            " 'Loss/regularization_loss': 0.14032724,\n",
            " 'Loss/total_loss': 0.2854181,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0627 18:48:14.650998 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.11458485,\n",
            " 'Loss/localization_loss': 0.030506015,\n",
            " 'Loss/regularization_loss': 0.14032724,\n",
            " 'Loss/total_loss': 0.2854181,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.317s\n",
            "I0627 18:48:46.392609 139980769736576 model_lib_v2.py:707] Step 2100 per-step time 0.317s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09183243,\n",
            " 'Loss/localization_loss': 0.04884779,\n",
            " 'Loss/regularization_loss': 0.13963848,\n",
            " 'Loss/total_loss': 0.2803187,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0627 18:48:46.392912 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.09183243,\n",
            " 'Loss/localization_loss': 0.04884779,\n",
            " 'Loss/regularization_loss': 0.13963848,\n",
            " 'Loss/total_loss': 0.2803187,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.314s\n",
            "I0627 18:49:17.791747 139980769736576 model_lib_v2.py:707] Step 2200 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09395153,\n",
            " 'Loss/localization_loss': 0.03732755,\n",
            " 'Loss/regularization_loss': 0.13893755,\n",
            " 'Loss/total_loss': 0.27021664,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0627 18:49:17.792038 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.09395153,\n",
            " 'Loss/localization_loss': 0.03732755,\n",
            " 'Loss/regularization_loss': 0.13893755,\n",
            " 'Loss/total_loss': 0.27021664,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.313s\n",
            "I0627 18:49:49.141141 139980769736576 model_lib_v2.py:707] Step 2300 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13378645,\n",
            " 'Loss/localization_loss': 0.037966058,\n",
            " 'Loss/regularization_loss': 0.13820031,\n",
            " 'Loss/total_loss': 0.30995283,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0627 18:49:49.141523 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13378645,\n",
            " 'Loss/localization_loss': 0.037966058,\n",
            " 'Loss/regularization_loss': 0.13820031,\n",
            " 'Loss/total_loss': 0.30995283,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.312s\n",
            "I0627 18:50:20.343667 139980769736576 model_lib_v2.py:707] Step 2400 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10075756,\n",
            " 'Loss/localization_loss': 0.015902845,\n",
            " 'Loss/regularization_loss': 0.13755456,\n",
            " 'Loss/total_loss': 0.25421497,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0627 18:50:20.343977 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.10075756,\n",
            " 'Loss/localization_loss': 0.015902845,\n",
            " 'Loss/regularization_loss': 0.13755456,\n",
            " 'Loss/total_loss': 0.25421497,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.313s\n",
            "I0627 18:50:51.671576 139980769736576 model_lib_v2.py:707] Step 2500 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09429587,\n",
            " 'Loss/localization_loss': 0.044484135,\n",
            " 'Loss/regularization_loss': 0.1368319,\n",
            " 'Loss/total_loss': 0.27561188,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0627 18:50:51.671858 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.09429587,\n",
            " 'Loss/localization_loss': 0.044484135,\n",
            " 'Loss/regularization_loss': 0.1368319,\n",
            " 'Loss/total_loss': 0.27561188,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.313s\n",
            "I0627 18:51:22.927348 139980769736576 model_lib_v2.py:707] Step 2600 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06640238,\n",
            " 'Loss/localization_loss': 0.020304248,\n",
            " 'Loss/regularization_loss': 0.13614745,\n",
            " 'Loss/total_loss': 0.22285408,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0627 18:51:22.927634 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.06640238,\n",
            " 'Loss/localization_loss': 0.020304248,\n",
            " 'Loss/regularization_loss': 0.13614745,\n",
            " 'Loss/total_loss': 0.22285408,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.314s\n",
            "I0627 18:51:54.336632 139980769736576 model_lib_v2.py:707] Step 2700 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07348554,\n",
            " 'Loss/localization_loss': 0.022919947,\n",
            " 'Loss/regularization_loss': 0.13543831,\n",
            " 'Loss/total_loss': 0.2318438,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0627 18:51:54.336978 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07348554,\n",
            " 'Loss/localization_loss': 0.022919947,\n",
            " 'Loss/regularization_loss': 0.13543831,\n",
            " 'Loss/total_loss': 0.2318438,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.314s\n",
            "I0627 18:52:25.737282 139980769736576 model_lib_v2.py:707] Step 2800 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07718706,\n",
            " 'Loss/localization_loss': 0.03171573,\n",
            " 'Loss/regularization_loss': 0.1347335,\n",
            " 'Loss/total_loss': 0.24363628,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0627 18:52:25.737610 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07718706,\n",
            " 'Loss/localization_loss': 0.03171573,\n",
            " 'Loss/regularization_loss': 0.1347335,\n",
            " 'Loss/total_loss': 0.24363628,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.316s\n",
            "I0627 18:52:57.372922 139980769736576 model_lib_v2.py:707] Step 2900 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068169974,\n",
            " 'Loss/localization_loss': 0.03226415,\n",
            " 'Loss/regularization_loss': 0.13404065,\n",
            " 'Loss/total_loss': 0.23447478,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0627 18:52:57.373291 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.068169974,\n",
            " 'Loss/localization_loss': 0.03226415,\n",
            " 'Loss/regularization_loss': 0.13404065,\n",
            " 'Loss/total_loss': 0.23447478,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.314s\n",
            "I0627 18:53:28.804895 139980769736576 model_lib_v2.py:707] Step 3000 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10360268,\n",
            " 'Loss/localization_loss': 0.01467509,\n",
            " 'Loss/regularization_loss': 0.13337325,\n",
            " 'Loss/total_loss': 0.25165102,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0627 18:53:28.805213 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.10360268,\n",
            " 'Loss/localization_loss': 0.01467509,\n",
            " 'Loss/regularization_loss': 0.13337325,\n",
            " 'Loss/total_loss': 0.25165102,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.319s\n",
            "I0627 18:54:00.686905 139980769736576 model_lib_v2.py:707] Step 3100 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06676074,\n",
            " 'Loss/localization_loss': 0.019269675,\n",
            " 'Loss/regularization_loss': 0.13271506,\n",
            " 'Loss/total_loss': 0.21874547,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0627 18:54:00.687258 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.06676074,\n",
            " 'Loss/localization_loss': 0.019269675,\n",
            " 'Loss/regularization_loss': 0.13271506,\n",
            " 'Loss/total_loss': 0.21874547,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.314s\n",
            "I0627 18:54:32.085503 139980769736576 model_lib_v2.py:707] Step 3200 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07274292,\n",
            " 'Loss/localization_loss': 0.018699192,\n",
            " 'Loss/regularization_loss': 0.13205925,\n",
            " 'Loss/total_loss': 0.22350135,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0627 18:54:32.085793 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07274292,\n",
            " 'Loss/localization_loss': 0.018699192,\n",
            " 'Loss/regularization_loss': 0.13205925,\n",
            " 'Loss/total_loss': 0.22350135,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.313s\n",
            "I0627 18:55:03.364315 139980769736576 model_lib_v2.py:707] Step 3300 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13639045,\n",
            " 'Loss/localization_loss': 0.015150666,\n",
            " 'Loss/regularization_loss': 0.1313673,\n",
            " 'Loss/total_loss': 0.2829084,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0627 18:55:03.364629 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13639045,\n",
            " 'Loss/localization_loss': 0.015150666,\n",
            " 'Loss/regularization_loss': 0.1313673,\n",
            " 'Loss/total_loss': 0.2829084,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.316s\n",
            "I0627 18:55:35.009424 139980769736576 model_lib_v2.py:707] Step 3400 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07786687,\n",
            " 'Loss/localization_loss': 0.033376887,\n",
            " 'Loss/regularization_loss': 0.13072333,\n",
            " 'Loss/total_loss': 0.24196708,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0627 18:55:35.009724 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07786687,\n",
            " 'Loss/localization_loss': 0.033376887,\n",
            " 'Loss/regularization_loss': 0.13072333,\n",
            " 'Loss/total_loss': 0.24196708,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.315s\n",
            "I0627 18:56:06.494818 139980769736576 model_lib_v2.py:707] Step 3500 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.073505394,\n",
            " 'Loss/localization_loss': 0.019961508,\n",
            " 'Loss/regularization_loss': 0.13008352,\n",
            " 'Loss/total_loss': 0.22355041,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0627 18:56:06.495146 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.073505394,\n",
            " 'Loss/localization_loss': 0.019961508,\n",
            " 'Loss/regularization_loss': 0.13008352,\n",
            " 'Loss/total_loss': 0.22355041,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.316s\n",
            "I0627 18:56:38.099841 139980769736576 model_lib_v2.py:707] Step 3600 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08615928,\n",
            " 'Loss/localization_loss': 0.033422027,\n",
            " 'Loss/regularization_loss': 0.12941353,\n",
            " 'Loss/total_loss': 0.24899484,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0627 18:56:38.100135 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.08615928,\n",
            " 'Loss/localization_loss': 0.033422027,\n",
            " 'Loss/regularization_loss': 0.12941353,\n",
            " 'Loss/total_loss': 0.24899484,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.314s\n",
            "I0627 18:57:09.489616 139980769736576 model_lib_v2.py:707] Step 3700 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08730994,\n",
            " 'Loss/localization_loss': 0.022719918,\n",
            " 'Loss/regularization_loss': 0.12874234,\n",
            " 'Loss/total_loss': 0.2387722,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0627 18:57:09.489931 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.08730994,\n",
            " 'Loss/localization_loss': 0.022719918,\n",
            " 'Loss/regularization_loss': 0.12874234,\n",
            " 'Loss/total_loss': 0.2387722,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.314s\n",
            "I0627 18:57:40.883970 139980769736576 model_lib_v2.py:707] Step 3800 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06468252,\n",
            " 'Loss/localization_loss': 0.019513331,\n",
            " 'Loss/regularization_loss': 0.128159,\n",
            " 'Loss/total_loss': 0.21235485,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0627 18:57:40.884264 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.06468252,\n",
            " 'Loss/localization_loss': 0.019513331,\n",
            " 'Loss/regularization_loss': 0.128159,\n",
            " 'Loss/total_loss': 0.21235485,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.314s\n",
            "I0627 18:58:12.272268 139980769736576 model_lib_v2.py:707] Step 3900 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081966564,\n",
            " 'Loss/localization_loss': 0.030854007,\n",
            " 'Loss/regularization_loss': 0.12751836,\n",
            " 'Loss/total_loss': 0.24033892,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0627 18:58:12.272609 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.081966564,\n",
            " 'Loss/localization_loss': 0.030854007,\n",
            " 'Loss/regularization_loss': 0.12751836,\n",
            " 'Loss/total_loss': 0.24033892,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.314s\n",
            "I0627 18:58:43.647015 139980769736576 model_lib_v2.py:707] Step 4000 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.072620004,\n",
            " 'Loss/localization_loss': 0.016600743,\n",
            " 'Loss/regularization_loss': 0.1268464,\n",
            " 'Loss/total_loss': 0.21606715,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0627 18:58:43.647357 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.072620004,\n",
            " 'Loss/localization_loss': 0.016600743,\n",
            " 'Loss/regularization_loss': 0.1268464,\n",
            " 'Loss/total_loss': 0.21606715,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.319s\n",
            "I0627 18:59:15.557590 139980769736576 model_lib_v2.py:707] Step 4100 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12214544,\n",
            " 'Loss/localization_loss': 0.021721417,\n",
            " 'Loss/regularization_loss': 0.12622723,\n",
            " 'Loss/total_loss': 0.2700941,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0627 18:59:15.557905 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12214544,\n",
            " 'Loss/localization_loss': 0.021721417,\n",
            " 'Loss/regularization_loss': 0.12622723,\n",
            " 'Loss/total_loss': 0.2700941,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.313s\n",
            "I0627 18:59:46.848702 139980769736576 model_lib_v2.py:707] Step 4200 per-step time 0.313s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.090250835,\n",
            " 'Loss/localization_loss': 0.030712273,\n",
            " 'Loss/regularization_loss': 0.12559344,\n",
            " 'Loss/total_loss': 0.24655655,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0627 18:59:46.848998 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.090250835,\n",
            " 'Loss/localization_loss': 0.030712273,\n",
            " 'Loss/regularization_loss': 0.12559344,\n",
            " 'Loss/total_loss': 0.24655655,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.314s\n",
            "I0627 19:00:18.282346 139980769736576 model_lib_v2.py:707] Step 4300 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05697034,\n",
            " 'Loss/localization_loss': 0.012023003,\n",
            " 'Loss/regularization_loss': 0.12493471,\n",
            " 'Loss/total_loss': 0.19392806,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0627 19:00:18.282679 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.05697034,\n",
            " 'Loss/localization_loss': 0.012023003,\n",
            " 'Loss/regularization_loss': 0.12493471,\n",
            " 'Loss/total_loss': 0.19392806,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.315s\n",
            "I0627 19:00:49.774697 139980769736576 model_lib_v2.py:707] Step 4400 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06796249,\n",
            " 'Loss/localization_loss': 0.015183012,\n",
            " 'Loss/regularization_loss': 0.12427848,\n",
            " 'Loss/total_loss': 0.20742399,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0627 19:00:49.774991 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.06796249,\n",
            " 'Loss/localization_loss': 0.015183012,\n",
            " 'Loss/regularization_loss': 0.12427848,\n",
            " 'Loss/total_loss': 0.20742399,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.315s\n",
            "I0627 19:01:21.307938 139980769736576 model_lib_v2.py:707] Step 4500 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11471155,\n",
            " 'Loss/localization_loss': 0.014057357,\n",
            " 'Loss/regularization_loss': 0.12365318,\n",
            " 'Loss/total_loss': 0.2524221,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0627 19:01:21.308227 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.11471155,\n",
            " 'Loss/localization_loss': 0.014057357,\n",
            " 'Loss/regularization_loss': 0.12365318,\n",
            " 'Loss/total_loss': 0.2524221,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.315s\n",
            "I0627 19:01:52.845426 139980769736576 model_lib_v2.py:707] Step 4600 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14015226,\n",
            " 'Loss/localization_loss': 0.032161348,\n",
            " 'Loss/regularization_loss': 0.123091176,\n",
            " 'Loss/total_loss': 0.2954048,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0627 19:01:52.845775 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.14015226,\n",
            " 'Loss/localization_loss': 0.032161348,\n",
            " 'Loss/regularization_loss': 0.123091176,\n",
            " 'Loss/total_loss': 0.2954048,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.314s\n",
            "I0627 19:02:24.226623 139980769736576 model_lib_v2.py:707] Step 4700 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07984306,\n",
            " 'Loss/localization_loss': 0.017256968,\n",
            " 'Loss/regularization_loss': 0.12249619,\n",
            " 'Loss/total_loss': 0.2195962,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0627 19:02:24.226928 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.07984306,\n",
            " 'Loss/localization_loss': 0.017256968,\n",
            " 'Loss/regularization_loss': 0.12249619,\n",
            " 'Loss/total_loss': 0.2195962,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.315s\n",
            "I0627 19:02:55.754778 139980769736576 model_lib_v2.py:707] Step 4800 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15225206,\n",
            " 'Loss/localization_loss': 0.048052188,\n",
            " 'Loss/regularization_loss': 0.12194118,\n",
            " 'Loss/total_loss': 0.32224542,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0627 19:02:55.755072 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.15225206,\n",
            " 'Loss/localization_loss': 0.048052188,\n",
            " 'Loss/regularization_loss': 0.12194118,\n",
            " 'Loss/total_loss': 0.32224542,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.314s\n",
            "I0627 19:03:27.161996 139980769736576 model_lib_v2.py:707] Step 4900 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046785902,\n",
            " 'Loss/localization_loss': 0.007842853,\n",
            " 'Loss/regularization_loss': 0.12132878,\n",
            " 'Loss/total_loss': 0.17595753,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0627 19:03:27.162292 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.046785902,\n",
            " 'Loss/localization_loss': 0.007842853,\n",
            " 'Loss/regularization_loss': 0.12132878,\n",
            " 'Loss/total_loss': 0.17595753,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.315s\n",
            "I0627 19:03:58.708868 139980769736576 model_lib_v2.py:707] Step 5000 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05493406,\n",
            " 'Loss/localization_loss': 0.008644803,\n",
            " 'Loss/regularization_loss': 0.120716445,\n",
            " 'Loss/total_loss': 0.1842953,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0627 19:03:58.709202 139980769736576 model_lib_v2.py:708] {'Loss/classification_loss': 0.05493406,\n",
            " 'Loss/localization_loss': 0.008644803,\n",
            " 'Loss/regularization_loss': 0.120716445,\n",
            " 'Loss/total_loss': 0.1842953,\n",
            " 'learning_rate': 0.078691795}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "85aff75d-0f55-418d-8749-e8c836f7cadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_mobilenet --pipeline_config_path=Tensorflow/workspace/models/my_mobilenet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_mobilenet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "outputId": "39b51429-26a9-4438-8710-d8f55cdae840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0627 19:05:06.283538 139942201255808 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0627 19:05:06.283741 139942201255808 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0627 19:05:06.283829 139942201255808 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0627 19:05:06.283916 139942201255808 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0627 19:05:06.284029 139942201255808 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-06-27 19:05:07.093841: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0627 19:05:07.250828 139942201255808 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0627 19:05:07.251071 139942201255808 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0627 19:05:07.251167 139942201255808 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0627 19:05:07.251247 139942201255808 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0627 19:05:07.253017 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0627 19:05:07.271764 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0627 19:05:11.100110 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 19:05:12.172166 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_mobilenet\n",
            "I0627 19:05:14.552349 139942201255808 checkpoint_utils.py:136] Waiting for new checkpoint at Tensorflow/workspace/models/my_mobilenet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_mobilenet/ckpt-6\n",
            "I0627 19:05:14.553275 139942201255808 checkpoint_utils.py:145] Found new checkpoint at Tensorflow/workspace/models/my_mobilenet/ckpt-6\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 19:05:38.495527 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0627 19:05:38.504642 139942201255808 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0627 19:05:38.620913 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Performing evaluation on 90 images.\n",
            "I0627 19:05:55.729709 139942201255808 coco_evaluation.py:293] Performing evaluation on 90 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 19:05:55.730615 139942201255808 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0627 19:05:55.735398 139942201255808 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.844\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
            "INFO:tensorflow:Eval metrics at step 5000\n",
            "I0627 19:05:56.399830 139942201255808 model_lib_v2.py:1015] Eval metrics at step 5000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.555282\n",
            "I0627 19:05:56.402926 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.555282\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.670982\n",
            "I0627 19:05:56.404348 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.670982\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.642733\n",
            "I0627 19:05:56.405687 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.642733\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.227190\n",
            "I0627 19:05:56.407018 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.227190\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.666235\n",
            "I0627 19:05:56.408271 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.666235\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.357013\n",
            "I0627 19:05:56.409517 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.357013\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.263208\n",
            "I0627 19:05:56.410752 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.263208\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.775502\n",
            "I0627 19:05:56.411961 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.775502\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.787777\n",
            "I0627 19:05:56.413152 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.787777\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.473969\n",
            "I0627 19:05:56.414437 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.473969\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.843936\n",
            "I0627 19:05:56.415684 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.843936\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.383333\n",
            "I0627 19:05:56.416972 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.383333\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.036713\n",
            "I0627 19:05:56.417918 139942201255808 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.036713\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.184387\n",
            "I0627 19:05:56.418925 139942201255808 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.184387\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.120710\n",
            "I0627 19:05:56.419934 139942201255808 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.120710\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.341810\n",
            "I0627 19:05:56.420908 139942201255808 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.341810\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n",
            "    time.sleep(time_to_next_eval)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'IMG_4317_wb8.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "647b19f0-eba6-4752-de24-8605bf6a18c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mais Training and Detection.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "12e2997e1db19daaf1ff42dd12ad38a26824f5495ce8e00160cc6cb4513d56f8"
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}