{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderPidodnya/MaisRecognition/blob/main/Mais_Training_and_Detection_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only for colab\n",
        "!pip uninstall tensorflow -q\n",
        "#!pip install tensorflow==2.7.0\n",
        "!pip install tensorflow==2.8 -q\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "#restart kernel"
      ],
      "metadata": {
        "id": "KmjTju7b2fFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a038ea-1578-4f8f-8072-6d8f7a45e59a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed (y/n)? y\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 28.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 63.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\n",
            "tensorflow-text 2.9.0 requires tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "146BB11JpfDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdf1302-cc7a-45bb-c98b-6b860cce21f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_mobilenet' \n",
        "#PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "#PRETRAINED_MODEL_NAME = 'ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz'\n",
        "#PRETRAINED_MODEL_NAME = 'efficientdet_d6_coco17_tpu-32'\n",
        "#PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_8tIWtKd0-F",
        "outputId": "72be4ec3-3cf8-47ab-bd89-38485e6f09c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.21.6', '2.8.0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "DwPu62ZDc_ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TE6vguv1vcW",
        "outputId": "f4f0e9d3-92f9-4096-d32f-397a11b48911"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LABELMAP': 'Tensorflow/workspace/annotations/label_map.pbtxt',\n",
              " 'PIPELINE_CONFIG': 'Tensorflow/workspace/models/my_mobilenet/pipeline.config',\n",
              " 'TF_RECORD_SCRIPT': 'Tensorflow/scripts/generate_tfrecord.py'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRIABN0_Xhfc"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bed80d6-bdd7-4018-decd-44e0fb0bb6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 74707, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 74707 (delta 102), reused 151 (delta 79), pack-reused 74512\u001b[K\n",
            "Receiving objects: 100% (74707/74707), 580.41 MiB | 17.30 MiB/s, done.\n",
            "Resolving deltas: 100% (52996/52996), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0cadeb-ccdc-4215-cf41-6c778e166983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.39.0-cp37-cp37m-manylinux2010_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 88 kB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.2 kB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 54.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 60.7 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694695 sha256=dae32b0122a7e0f87050cd3ac4bb667dc9a3ff14d0483989df49a133bea78e7b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ymdnn2eh/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=0bbeb9fc92d687b76ff8f82e41dacf85d7255057682550ce15655322d8ba36b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=1d15d9bdae72eb63f1139c879d04d7fa69c97d3f0e61a9d64701b6fb8cb0f3eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=72c0d4ebd5ed643dd7769b86ee99ea9d608ece2d2cacf330b4dd557b9378115a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=55a01e3b78cca13ceb9de17ffbe980836e1beb25d9330dfe9b826bd0ccd011fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.2 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.3 portalocker-2.4.0 proto-plus-1.20.6 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.0 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AsxYBmeFYRzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceb4195-6eea-4c6b-d4d5-3b985e3aa8c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyDGNiKUXhfg",
        "outputId": "1714dc55-93a6-4814-cca6-53019b22eea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-06-24 18:39:23.814948: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0624 18:39:24.075839 140413450200960 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.67s\n",
            "I0624 18:39:24.487368 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "I0624 18:39:25.058763 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "I0624 18:39:25.348471 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "I0624 18:39:25.613681 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.13s\n",
            "I0624 18:39:27.746114 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0624 18:39:27.747106 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0624 18:39:27.771192 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0624 18:39:27.787100 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0624 18:39:27.801881 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "I0624 18:39:27.905455 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0624 18:39:27.998696 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0624 18:39:28.094038 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "I0624 18:39:28.190659 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0624 18:39:28.289904 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0624 18:39:28.319995 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0624 18:39:28.512298 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0624 18:39:28.512462 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0624 18:39:28.512537 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0624 18:39:28.514830 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:28.533102 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:28.533249 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:28.602330 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:28.602505 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:28.782766 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:28.782979 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:28.966632 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:28.966841 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:29.236128 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:29.236324 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:29.485214 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:29.485407 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:29.861942 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:29.862168 140413450200960 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0624 18:39:29.956846 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0624 18:39:29.996822 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:30.247163 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0624 18:39:30.247375 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0624 18:39:30.247462 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0624 18:39:30.249339 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:30.270002 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:30.270237 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:30.419929 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:30.420140 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:30.661950 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:30.662116 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:30.913701 140413450200960 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0624 18:39:30.913905 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:31.241917 140413450200960 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0624 18:39:31.242106 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:31.580046 140413450200960 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0624 18:39:31.580236 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:31.981278 140413450200960 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0624 18:39:31.981448 140413450200960 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0624 18:39:32.132890 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0624 18:39:32.164004 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:32.228915 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0624 18:39:32.229134 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0624 18:39:32.229220 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0624 18:39:32.231701 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:32.248402 140413450200960 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0624 18:39:32.248544 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:32.379191 140413450200960 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0624 18:39:32.379358 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:32.618590 140413450200960 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0624 18:39:32.618758 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:32.863414 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:32.863576 140413450200960 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0624 18:39:33.186033 140413450200960 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0624 18:39:33.186204 140413450200960 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0624 18:39:33.514497 140413450200960 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0624 18:39:33.514669 140413450200960 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0624 18:39:33.928471 140413450200960 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0624 18:39:33.928666 140413450200960 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0624 18:39:34.087895 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0624 18:39:34.117861 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:34.180376 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0624 18:39:34.180539 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0624 18:39:34.180616 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0624 18:39:34.182273 140413450200960 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0624 18:39:34.198441 140413450200960 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0624 18:39:34.198564 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:34.319888 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:34.320075 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:34.554149 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:34.554315 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:34.784173 140413450200960 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0624 18:39:34.784339 140413450200960 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0624 18:39:35.184455 140413450200960 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0624 18:39:35.184628 140413450200960 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0624 18:39:35.768588 140413450200960 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0624 18:39:35.768757 140413450200960 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0624 18:39:36.262497 140413450200960 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0624 18:39:36.262683 140413450200960 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0624 18:39:36.427155 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0624 18:39:36.456774 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:36.524399 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0624 18:39:36.524572 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0624 18:39:36.524662 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0624 18:39:36.526358 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:36.548913 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:36.549085 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:36.685201 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:36.685396 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:37.021621 140413450200960 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0624 18:39:37.021805 140413450200960 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0624 18:39:37.345455 140413450200960 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0624 18:39:37.345642 140413450200960 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0624 18:39:37.852180 140413450200960 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0624 18:39:37.852345 140413450200960 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0624 18:39:38.367744 140413450200960 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0624 18:39:38.367938 140413450200960 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0624 18:39:39.040249 140413450200960 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0624 18:39:39.040425 140413450200960 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0624 18:39:39.200330 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0624 18:39:39.230144 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:39.315209 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0624 18:39:39.315360 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0624 18:39:39.315432 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0624 18:39:39.316946 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:39.333431 140413450200960 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0624 18:39:39.333545 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:39.525480 140413450200960 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0624 18:39:39.525651 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:39.915038 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:39.915217 140413450200960 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0624 18:39:40.314213 140413450200960 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0624 18:39:40.314378 140413450200960 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0624 18:39:40.873874 140413450200960 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0624 18:39:40.874053 140413450200960 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0624 18:39:41.646679 140413450200960 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0624 18:39:41.646853 140413450200960 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0624 18:39:42.367084 140413450200960 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0624 18:39:42.367267 140413450200960 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0624 18:39:42.602052 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0624 18:39:42.630858 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:42.715494 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0624 18:39:42.715651 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0624 18:39:42.715740 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0624 18:39:42.717359 140413450200960 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0624 18:39:42.734271 140413450200960 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0624 18:39:42.734390 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:42.922067 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:42.922235 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:43.407027 140413450200960 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0624 18:39:43.407192 140413450200960 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0624 18:39:43.880269 140413450200960 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0624 18:39:43.880439 140413450200960 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0624 18:39:44.528771 140413450200960 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0624 18:39:44.528967 140413450200960 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0624 18:39:45.161717 140413450200960 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0624 18:39:45.161921 140413450200960 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0624 18:39:46.061461 140413450200960 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0624 18:39:46.061674 140413450200960 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0624 18:39:46.302970 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0624 18:39:46.333019 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0624 18:39:46.430605 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0624 18:39:46.430757 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0624 18:39:46.430827 140413450200960 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0624 18:39:46.432527 140413450200960 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0624 18:39:46.447967 140413450200960 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0624 18:39:46.448073 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:46.712241 140413450200960 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0624 18:39:46.712412 140413450200960 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0624 18:39:47.510081 140413450200960 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0624 18:39:47.510275 140413450200960 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0624 18:39:48.076568 140413450200960 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0624 18:39:48.076750 140413450200960 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0624 18:39:48.895634 140413450200960 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0624 18:39:48.895803 140413450200960 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0624 18:39:49.678145 140413450200960 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0624 18:39:49.678318 140413450200960 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0624 18:39:50.717824 140413450200960 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0624 18:39:50.718010 140413450200960 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0624 18:39:51.035020 140413450200960 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0624 18:39:51.077247 140413450200960 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.89s\n",
            "I0624 18:39:51.209360 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.89s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0624 18:39:51.215465 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0624 18:39:51.217306 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0624 18:39:51.217834 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0624 18:39:51.219449 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0624 18:39:51.220887 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0624 18:39:51.221374 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0624 18:39:51.222406 140413450200960 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.403s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -q '/content/drive/MyDrive/diploma/base/stampsignatures.zip' -d /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "SAV0XKfee_Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/collectedimages.zip' -d /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "_ZUAY7nUhWyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Tensorflow/workspace/images\n",
        "!mkdir  /content/Tensorflow/workspace/images"
      ],
      "metadata": {
        "id": "yu536zT3FMAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zOWvs1g-Xhfh",
        "outputId": "a973095c-782a-40fe-9acd-4efa11d250f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.24.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.20.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.19.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip install tensorflow-gpu --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zJrwUEysXhfi",
        "outputId": "951d7309-02ce-4928-8ae1-4bc959ed0a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: protobuf 3.15.7\n",
            "Uninstalling protobuf-3.15.7:\n",
            "  Successfully uninstalled protobuf-3.15.7\n",
            "Found existing installation: matplotlib 3.4.1\n",
            "Uninstalling matplotlib-3.4.1:\n",
            "  Successfully uninstalled matplotlib-3.4.1\n",
            "Collecting protobuf"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.28.0 requires crcmod<2.0,>=1.7, which is not installed.\n",
            "apache-beam 2.28.0 requires dill<0.3.2,>=0.3.1.1, which is not installed.\n",
            "apache-beam 2.28.0 requires fastavro<2,>=0.21.4, which is not installed.\n",
            "apache-beam 2.28.0 requires future<1.0.0,>=0.18.2, which is not installed.\n",
            "apache-beam 2.28.0 requires grpcio<2,>=1.29.0, which is not installed.\n",
            "apache-beam 2.28.0 requires hdfs<3.0.0,>=2.1.0, which is not installed.\n",
            "apache-beam 2.28.0 requires httplib2<0.18.0,>=0.8, which is not installed.\n",
            "apache-beam 2.28.0 requires mock<3.0.0,>=1.0.1, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires astunparse~=1.6.3, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires flatbuffers~=1.12.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires gast==0.4.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires google-pasta~=0.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires grpcio~=1.34.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires h5py~=3.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-nightly~=2.5.0.dev, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-preprocessing~=1.1.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires opt-einsum~=3.3.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tensorboard~=2.4, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires termcolor~=1.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tf-estimator-nightly==2.5.0.dev2021032501, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires wrapt~=1.12.1, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires attrs>=18.1.0, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires dill, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires future, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires importlib-resources, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires promise, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tensorflow-metadata, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires termcolor, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tqdm, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-api-core[grpc]<2.0.0dev,>=1.23.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-cloud-core<2.0dev,>=1.4.1, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-resumable-media<2.0dev,>=0.6.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires packaging>=14.3, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires proto-plus>=1.10.0, which is not installed.\n",
            "apache-beam 2.28.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you have avro-python3 1.10.2 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading protobuf-3.15.7-cp37-cp37m-win_amd64.whl (904 kB)\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached matplotlib-3.2.0-cp37-cp37m-win_amd64.whl (9.2 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\cycler-0.10.0-py3.7.egg (from matplotlib==3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\kiwisolver-1.3.1-py3.7-win-amd64.egg (from matplotlib==3.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\pyparsing-3.0.0b2-py3.7.egg (from matplotlib==3.2) (3.0.0b2)\n",
            "Requirement already satisfied: numpy>=1.11 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: six in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from cycler>=0.10->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.15.7\n"
          ]
        }
      ],
      "source": [
        "#!pip uninstall protobuf matplotlib -y\n",
        "#!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F3WUN9wGXhfi"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list  #curr"
      ],
      "metadata": {
        "id": "ofaQDPMdfKK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fQMXEUHDXhfj"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "1afbe6c7-c8ad-4d24-fe8b-496d994eee88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 18:28:18--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.24.128, 2404:6800:4003:c00::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.24.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  50.1MB/s    in 0.4s    \n",
            "\n",
            "2022-06-27 18:28:20 (50.1 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'thumbsup', 'id':1},\n",
        "          {'name':'thumbsdown', 'id':2}, \n",
        "          {'name':'thankyou', 'id':3},\n",
        "          {'name':'fist', 'id':4},\n",
        "          {'name':'united', 'id':5},\n",
        "          {'name':'victory', 'id':6}]\n",
        "          \n",
        "labels = [{'name' : 'mais', 'id':1},\n",
        "          {'name' : 'dill', 'id':2},\n",
        "          {'name' : 'buckwheat', 'id':3},\n",
        "          {'name' : 'other', 'id':4}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item {\\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KWpb_BVUpfDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bedd84d-8919-42b9-d3c2-196ee61d1974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resources = '/content/resources'\n",
        "if not os.path.exists(resources):\n",
        "  !mkdir {resources}\n",
        "!git clone https://github.com/AlexanderPidodnya/MaisRecognition {resources}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVl2vyTcITYT",
        "outputId": "4a5b09e3-3189-45cc-a3e5-3469adef240c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/resources'...\n",
            "remote: Enumerating objects: 1949, done.\u001b[K\n",
            "remote: Counting objects: 100% (1879/1879), done.\u001b[K\n",
            "remote: Compressing objects: 100% (456/456), done.\u001b[K\n",
            "remote: Total 1949 (delta 1461), reused 1826 (delta 1411), pack-reused 70\u001b[K\n",
            "Receiving objects: 100% (1949/1949), 109.92 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (1482/1482), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coping from resources\n",
        "import glob, shutil\n",
        "onColab = os.name =='posix' \n",
        "if not onColab:\n",
        "\n",
        "  res_img = r'C:\\Users\\AdminAsus\\PycharmProjects\\MaisRecognition\\resources'\n",
        "  train_path = os.path.join(paths['IMAGE_PATH'], 'train')\n",
        "  test_path = os.path.join(paths['IMAGE_PATH'], 'test')\n",
        "  if not os.path.exists(train_path):\n",
        "      !mkdir {train_path}\n",
        "  if not os.path.exists(test_path):\n",
        "      !mkdir {test_path}\n",
        "if onColab:\n",
        "  res_img = r'/content/resources/SlicedImages_2'\n",
        "  train_path = os.path.join(paths['IMAGE_PATH'], 'train')\n",
        "  test_path = os.path.join(paths['IMAGE_PATH'], 'test')\n",
        "  if not os.path.exists(train_path):\n",
        "      !mkdir {train_path}\n",
        "  if not os.path.exists(test_path):\n",
        "      !mkdir {test_path}\n",
        "\n",
        "imgs = []\n",
        "rr = '.jpg'\n",
        "for img in os.listdir(res_img):\n",
        "  if rr in img.lower():\n",
        "    imgs.append(img[:-4])\n",
        "tr_k = len(imgs) * 0.8\n",
        "for i, img in enumerate(imgs):\n",
        "  fList = glob.glob(os.path.join(res_img, img+'*.*'))\n",
        "  \n",
        "  for f in fList:\n",
        "    #print(f)\n",
        "    if i<tr_k:\n",
        "      if onColab:\n",
        "        !cp {f} {train_path} \n",
        "      else:\n",
        "        !copy {f} {train_path} \n",
        "    else:\n",
        "      if onColab:\n",
        "        !cp {f} {test_path}        \n",
        "      else:\n",
        "        !copy {f} {test_path}        \n",
        "# may use a directive like !copy"
      ],
      "metadata": {
        "id": "clnGmzluIam0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "7e4a948e-7cfd-4279-bda5-394e1617b335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iySTyyTIkzgf",
        "outputId": "210fd1c5-af9e-455a-cb2f-c242421d76f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "e79575c0-ceda-458b-8f6b-31e036c3f678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7OjJvh4l3Yx",
        "outputId": "fdc8cbc0-284f-4472-b7cd-214311591e5c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 4\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 640\n",
              "        width: 640\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=15000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "adea26e9-0050-4d3d-b55c-838bee8ba451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_mobilenet --pipeline_config_path=Tensorflow/workspace/models/my_mobilenet/pipeline.config --num_train_steps=15000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6KpyP0zi2eK",
        "outputId": "63d55b5a-d125-464e-e623-c2bc63615e72"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i3ZsJR-qpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c5e0ff-1dee-4029-c768-1eb20775ffc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-27 19:32:33.086896: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0627 19:32:33.092967 140309799094144 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 15000\n",
            "I0627 19:32:33.096581 140309799094144 config_util.py:552] Maybe overwriting train_steps: 15000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0627 19:32:33.096746 140309799094144 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0627 19:32:33.241446 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0627 19:32:33.246451 140309799094144 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0627 19:32:33.246655 140309799094144 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0627 19:32:33.246746 140309799094144 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0627 19:32:33.246816 140309799094144 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0627 19:32:33.249080 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0627 19:32:33.267727 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0627 19:32:39.949635 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0627 19:32:42.716447 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 19:32:44.272711 140309799094144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0627 19:33:12.062210 140304663643904 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 5100 per-step time 0.637s\n",
            "I0627 19:34:15.475834 140309799094144 model_lib_v2.py:707] Step 5100 per-step time 0.637s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1059537,\n",
            " 'Loss/localization_loss': 0.028920434,\n",
            " 'Loss/regularization_loss': 0.12008828,\n",
            " 'Loss/total_loss': 0.2549624,\n",
            " 'learning_rate': 0.07862595}\n",
            "I0627 19:34:15.476222 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.1059537,\n",
            " 'Loss/localization_loss': 0.028920434,\n",
            " 'Loss/regularization_loss': 0.12008828,\n",
            " 'Loss/total_loss': 0.2549624,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.319s\n",
            "I0627 19:34:47.130949 140309799094144 model_lib_v2.py:707] Step 5200 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.069125175,\n",
            " 'Loss/localization_loss': 0.016981266,\n",
            " 'Loss/regularization_loss': 0.11951595,\n",
            " 'Loss/total_loss': 0.20562239,\n",
            " 'learning_rate': 0.07855851}\n",
            "I0627 19:34:47.131295 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.069125175,\n",
            " 'Loss/localization_loss': 0.016981266,\n",
            " 'Loss/regularization_loss': 0.11951595,\n",
            " 'Loss/total_loss': 0.20562239,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.321s\n",
            "I0627 19:35:19.278119 140309799094144 model_lib_v2.py:707] Step 5300 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06269211,\n",
            " 'Loss/localization_loss': 0.02136605,\n",
            " 'Loss/regularization_loss': 0.118972205,\n",
            " 'Loss/total_loss': 0.20303038,\n",
            " 'learning_rate': 0.07848949}\n",
            "I0627 19:35:19.278429 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06269211,\n",
            " 'Loss/localization_loss': 0.02136605,\n",
            " 'Loss/regularization_loss': 0.118972205,\n",
            " 'Loss/total_loss': 0.20303038,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.324s\n",
            "I0627 19:35:51.669891 140309799094144 model_lib_v2.py:707] Step 5400 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079414986,\n",
            " 'Loss/localization_loss': 0.018455712,\n",
            " 'Loss/regularization_loss': 0.11844572,\n",
            " 'Loss/total_loss': 0.21631642,\n",
            " 'learning_rate': 0.078418896}\n",
            "I0627 19:35:51.670300 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.079414986,\n",
            " 'Loss/localization_loss': 0.018455712,\n",
            " 'Loss/regularization_loss': 0.11844572,\n",
            " 'Loss/total_loss': 0.21631642,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.324s\n",
            "I0627 19:36:24.056518 140309799094144 model_lib_v2.py:707] Step 5500 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055077165,\n",
            " 'Loss/localization_loss': 0.014560432,\n",
            " 'Loss/regularization_loss': 0.11788931,\n",
            " 'Loss/total_loss': 0.18752691,\n",
            " 'learning_rate': 0.078346714}\n",
            "I0627 19:36:24.056816 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.055077165,\n",
            " 'Loss/localization_loss': 0.014560432,\n",
            " 'Loss/regularization_loss': 0.11788931,\n",
            " 'Loss/total_loss': 0.18752691,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.323s\n",
            "I0627 19:36:56.385208 140309799094144 model_lib_v2.py:707] Step 5600 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.110085264,\n",
            " 'Loss/localization_loss': 0.027445214,\n",
            " 'Loss/regularization_loss': 0.11730489,\n",
            " 'Loss/total_loss': 0.25483537,\n",
            " 'learning_rate': 0.07827295}\n",
            "I0627 19:36:56.385523 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.110085264,\n",
            " 'Loss/localization_loss': 0.027445214,\n",
            " 'Loss/regularization_loss': 0.11730489,\n",
            " 'Loss/total_loss': 0.25483537,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.322s\n",
            "I0627 19:37:28.549254 140309799094144 model_lib_v2.py:707] Step 5700 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08354722,\n",
            " 'Loss/localization_loss': 0.039900836,\n",
            " 'Loss/regularization_loss': 0.11673859,\n",
            " 'Loss/total_loss': 0.24018665,\n",
            " 'learning_rate': 0.07819763}\n",
            "I0627 19:37:28.549570 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.08354722,\n",
            " 'Loss/localization_loss': 0.039900836,\n",
            " 'Loss/regularization_loss': 0.11673859,\n",
            " 'Loss/total_loss': 0.24018665,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.322s\n",
            "I0627 19:38:00.703162 140309799094144 model_lib_v2.py:707] Step 5800 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.093360245,\n",
            " 'Loss/localization_loss': 0.017873965,\n",
            " 'Loss/regularization_loss': 0.1161877,\n",
            " 'Loss/total_loss': 0.22742191,\n",
            " 'learning_rate': 0.07812072}\n",
            "I0627 19:38:00.703521 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.093360245,\n",
            " 'Loss/localization_loss': 0.017873965,\n",
            " 'Loss/regularization_loss': 0.1161877,\n",
            " 'Loss/total_loss': 0.22742191,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.321s\n",
            "I0627 19:38:32.830734 140309799094144 model_lib_v2.py:707] Step 5900 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060702756,\n",
            " 'Loss/localization_loss': 0.026347613,\n",
            " 'Loss/regularization_loss': 0.11569939,\n",
            " 'Loss/total_loss': 0.20274976,\n",
            " 'learning_rate': 0.078042254}\n",
            "I0627 19:38:32.831060 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.060702756,\n",
            " 'Loss/localization_loss': 0.026347613,\n",
            " 'Loss/regularization_loss': 0.11569939,\n",
            " 'Loss/total_loss': 0.20274976,\n",
            " 'learning_rate': 0.078042254}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.323s\n",
            "I0627 19:39:05.161474 140309799094144 model_lib_v2.py:707] Step 6000 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09811907,\n",
            " 'Loss/localization_loss': 0.021156888,\n",
            " 'Loss/regularization_loss': 0.11514759,\n",
            " 'Loss/total_loss': 0.23442355,\n",
            " 'learning_rate': 0.07796223}\n",
            "I0627 19:39:05.161767 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.09811907,\n",
            " 'Loss/localization_loss': 0.021156888,\n",
            " 'Loss/regularization_loss': 0.11514759,\n",
            " 'Loss/total_loss': 0.23442355,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.282801 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.284103 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.286176 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.287057 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.289052 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.289934 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.291946 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.292826 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.294914 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0627 19:39:05.295785 140309799094144 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Step 6100 per-step time 0.326s\n",
            "I0627 19:39:37.795776 140309799094144 model_lib_v2.py:707] Step 6100 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07092685,\n",
            " 'Loss/localization_loss': 0.013110583,\n",
            " 'Loss/regularization_loss': 0.11461341,\n",
            " 'Loss/total_loss': 0.19865084,\n",
            " 'learning_rate': 0.077880636}\n",
            "I0627 19:39:37.796069 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07092685,\n",
            " 'Loss/localization_loss': 0.013110583,\n",
            " 'Loss/regularization_loss': 0.11461341,\n",
            " 'Loss/total_loss': 0.19865084,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.321s\n",
            "I0627 19:40:09.847674 140309799094144 model_lib_v2.py:707] Step 6200 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058322176,\n",
            " 'Loss/localization_loss': 0.013742863,\n",
            " 'Loss/regularization_loss': 0.11408404,\n",
            " 'Loss/total_loss': 0.18614909,\n",
            " 'learning_rate': 0.07779749}\n",
            "I0627 19:40:09.848027 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.058322176,\n",
            " 'Loss/localization_loss': 0.013742863,\n",
            " 'Loss/regularization_loss': 0.11408404,\n",
            " 'Loss/total_loss': 0.18614909,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.320s\n",
            "I0627 19:40:41.834530 140309799094144 model_lib_v2.py:707] Step 6300 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055840924,\n",
            " 'Loss/localization_loss': 0.021385882,\n",
            " 'Loss/regularization_loss': 0.113744855,\n",
            " 'Loss/total_loss': 0.19097166,\n",
            " 'learning_rate': 0.07771279}\n",
            "I0627 19:40:41.834836 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.055840924,\n",
            " 'Loss/localization_loss': 0.021385882,\n",
            " 'Loss/regularization_loss': 0.113744855,\n",
            " 'Loss/total_loss': 0.19097166,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.323s\n",
            "I0627 19:41:14.091096 140309799094144 model_lib_v2.py:707] Step 6400 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.093931735,\n",
            " 'Loss/localization_loss': 0.019063758,\n",
            " 'Loss/regularization_loss': 0.113219336,\n",
            " 'Loss/total_loss': 0.22621483,\n",
            " 'learning_rate': 0.077626534}\n",
            "I0627 19:41:14.091414 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.093931735,\n",
            " 'Loss/localization_loss': 0.019063758,\n",
            " 'Loss/regularization_loss': 0.113219336,\n",
            " 'Loss/total_loss': 0.22621483,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.321s\n",
            "I0627 19:41:46.180468 140309799094144 model_lib_v2.py:707] Step 6500 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053773537,\n",
            " 'Loss/localization_loss': 0.013342901,\n",
            " 'Loss/regularization_loss': 0.11269681,\n",
            " 'Loss/total_loss': 0.17981325,\n",
            " 'learning_rate': 0.077538736}\n",
            "I0627 19:41:46.180772 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.053773537,\n",
            " 'Loss/localization_loss': 0.013342901,\n",
            " 'Loss/regularization_loss': 0.11269681,\n",
            " 'Loss/total_loss': 0.17981325,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.321s\n",
            "I0627 19:42:18.256644 140309799094144 model_lib_v2.py:707] Step 6600 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068627745,\n",
            " 'Loss/localization_loss': 0.02590603,\n",
            " 'Loss/regularization_loss': 0.11217138,\n",
            " 'Loss/total_loss': 0.20670515,\n",
            " 'learning_rate': 0.077449396}\n",
            "I0627 19:42:18.256990 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.068627745,\n",
            " 'Loss/localization_loss': 0.02590603,\n",
            " 'Loss/regularization_loss': 0.11217138,\n",
            " 'Loss/total_loss': 0.20670515,\n",
            " 'learning_rate': 0.077449396}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.318s\n",
            "I0627 19:42:50.090423 140309799094144 model_lib_v2.py:707] Step 6700 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08589202,\n",
            " 'Loss/localization_loss': 0.034502994,\n",
            " 'Loss/regularization_loss': 0.11166716,\n",
            " 'Loss/total_loss': 0.23206219,\n",
            " 'learning_rate': 0.077358514}\n",
            "I0627 19:42:50.090709 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.08589202,\n",
            " 'Loss/localization_loss': 0.034502994,\n",
            " 'Loss/regularization_loss': 0.11166716,\n",
            " 'Loss/total_loss': 0.23206219,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.319s\n",
            "I0627 19:43:21.999043 140309799094144 model_lib_v2.py:707] Step 6800 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054654215,\n",
            " 'Loss/localization_loss': 0.0105485385,\n",
            " 'Loss/regularization_loss': 0.11115147,\n",
            " 'Loss/total_loss': 0.17635423,\n",
            " 'learning_rate': 0.0772661}\n",
            "I0627 19:43:21.999350 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.054654215,\n",
            " 'Loss/localization_loss': 0.0105485385,\n",
            " 'Loss/regularization_loss': 0.11115147,\n",
            " 'Loss/total_loss': 0.17635423,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.319s\n",
            "I0627 19:43:53.908156 140309799094144 model_lib_v2.py:707] Step 6900 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051329214,\n",
            " 'Loss/localization_loss': 0.0144782,\n",
            " 'Loss/regularization_loss': 0.11064263,\n",
            " 'Loss/total_loss': 0.17645004,\n",
            " 'learning_rate': 0.077172145}\n",
            "I0627 19:43:53.908498 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.051329214,\n",
            " 'Loss/localization_loss': 0.0144782,\n",
            " 'Loss/regularization_loss': 0.11064263,\n",
            " 'Loss/total_loss': 0.17645004,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.322s\n",
            "I0627 19:44:26.103521 140309799094144 model_lib_v2.py:707] Step 7000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051635586,\n",
            " 'Loss/localization_loss': 0.02079384,\n",
            " 'Loss/regularization_loss': 0.11018935,\n",
            " 'Loss/total_loss': 0.18261877,\n",
            " 'learning_rate': 0.07707667}\n",
            "I0627 19:44:26.103827 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.051635586,\n",
            " 'Loss/localization_loss': 0.02079384,\n",
            " 'Loss/regularization_loss': 0.11018935,\n",
            " 'Loss/total_loss': 0.18261877,\n",
            " 'learning_rate': 0.07707667}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.325s\n",
            "I0627 19:44:58.567542 140309799094144 model_lib_v2.py:707] Step 7100 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052261338,\n",
            " 'Loss/localization_loss': 0.0154656805,\n",
            " 'Loss/regularization_loss': 0.10971417,\n",
            " 'Loss/total_loss': 0.17744118,\n",
            " 'learning_rate': 0.07697967}\n",
            "I0627 19:44:58.567857 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.052261338,\n",
            " 'Loss/localization_loss': 0.0154656805,\n",
            " 'Loss/regularization_loss': 0.10971417,\n",
            " 'Loss/total_loss': 0.17744118,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.320s\n",
            "I0627 19:45:30.541804 140309799094144 model_lib_v2.py:707] Step 7200 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058190957,\n",
            " 'Loss/localization_loss': 0.016835742,\n",
            " 'Loss/regularization_loss': 0.109193645,\n",
            " 'Loss/total_loss': 0.18422034,\n",
            " 'learning_rate': 0.07688115}\n",
            "I0627 19:45:30.542107 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.058190957,\n",
            " 'Loss/localization_loss': 0.016835742,\n",
            " 'Loss/regularization_loss': 0.109193645,\n",
            " 'Loss/total_loss': 0.18422034,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.323s\n",
            "I0627 19:46:02.796397 140309799094144 model_lib_v2.py:707] Step 7300 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15547496,\n",
            " 'Loss/localization_loss': 0.018332839,\n",
            " 'Loss/regularization_loss': 0.10872588,\n",
            " 'Loss/total_loss': 0.28253368,\n",
            " 'learning_rate': 0.07678111}\n",
            "I0627 19:46:02.796737 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.15547496,\n",
            " 'Loss/localization_loss': 0.018332839,\n",
            " 'Loss/regularization_loss': 0.10872588,\n",
            " 'Loss/total_loss': 0.28253368,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.321s\n",
            "I0627 19:46:34.888401 140309799094144 model_lib_v2.py:707] Step 7400 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.080392316,\n",
            " 'Loss/localization_loss': 0.03512276,\n",
            " 'Loss/regularization_loss': 0.10821248,\n",
            " 'Loss/total_loss': 0.22372755,\n",
            " 'learning_rate': 0.076679565}\n",
            "I0627 19:46:34.888710 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.080392316,\n",
            " 'Loss/localization_loss': 0.03512276,\n",
            " 'Loss/regularization_loss': 0.10821248,\n",
            " 'Loss/total_loss': 0.22372755,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.323s\n",
            "I0627 19:47:07.218062 140309799094144 model_lib_v2.py:707] Step 7500 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.073164165,\n",
            " 'Loss/localization_loss': 0.024445362,\n",
            " 'Loss/regularization_loss': 0.10773514,\n",
            " 'Loss/total_loss': 0.20534468,\n",
            " 'learning_rate': 0.0765765}\n",
            "I0627 19:47:07.218690 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.073164165,\n",
            " 'Loss/localization_loss': 0.024445362,\n",
            " 'Loss/regularization_loss': 0.10773514,\n",
            " 'Loss/total_loss': 0.20534468,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.327s\n",
            "I0627 19:47:39.908854 140309799094144 model_lib_v2.py:707] Step 7600 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054172188,\n",
            " 'Loss/localization_loss': 0.01688737,\n",
            " 'Loss/regularization_loss': 0.10719913,\n",
            " 'Loss/total_loss': 0.17825869,\n",
            " 'learning_rate': 0.07647194}\n",
            "I0627 19:47:39.909182 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.054172188,\n",
            " 'Loss/localization_loss': 0.01688737,\n",
            " 'Loss/regularization_loss': 0.10719913,\n",
            " 'Loss/total_loss': 0.17825869,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.321s\n",
            "I0627 19:48:11.986612 140309799094144 model_lib_v2.py:707] Step 7700 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06471997,\n",
            " 'Loss/localization_loss': 0.018213715,\n",
            " 'Loss/regularization_loss': 0.10672116,\n",
            " 'Loss/total_loss': 0.18965484,\n",
            " 'learning_rate': 0.07636588}\n",
            "I0627 19:48:11.986940 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06471997,\n",
            " 'Loss/localization_loss': 0.018213715,\n",
            " 'Loss/regularization_loss': 0.10672116,\n",
            " 'Loss/total_loss': 0.18965484,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.324s\n",
            "I0627 19:48:44.345814 140309799094144 model_lib_v2.py:707] Step 7800 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13406414,\n",
            " 'Loss/localization_loss': 0.046649657,\n",
            " 'Loss/regularization_loss': 0.1062655,\n",
            " 'Loss/total_loss': 0.28697932,\n",
            " 'learning_rate': 0.07625833}\n",
            "I0627 19:48:44.346115 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.13406414,\n",
            " 'Loss/localization_loss': 0.046649657,\n",
            " 'Loss/regularization_loss': 0.1062655,\n",
            " 'Loss/total_loss': 0.28697932,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.321s\n",
            "I0627 19:49:16.489555 140309799094144 model_lib_v2.py:707] Step 7900 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.111748144,\n",
            " 'Loss/localization_loss': 0.07414007,\n",
            " 'Loss/regularization_loss': 0.10609331,\n",
            " 'Loss/total_loss': 0.29198152,\n",
            " 'learning_rate': 0.07614928}\n",
            "I0627 19:49:16.489857 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.111748144,\n",
            " 'Loss/localization_loss': 0.07414007,\n",
            " 'Loss/regularization_loss': 0.10609331,\n",
            " 'Loss/total_loss': 0.29198152,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.322s\n",
            "I0627 19:49:48.653668 140309799094144 model_lib_v2.py:707] Step 8000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050354697,\n",
            " 'Loss/localization_loss': 0.010392321,\n",
            " 'Loss/regularization_loss': 0.10558092,\n",
            " 'Loss/total_loss': 0.16632794,\n",
            " 'learning_rate': 0.07603875}\n",
            "I0627 19:49:48.654034 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.050354697,\n",
            " 'Loss/localization_loss': 0.010392321,\n",
            " 'Loss/regularization_loss': 0.10558092,\n",
            " 'Loss/total_loss': 0.16632794,\n",
            " 'learning_rate': 0.07603875}\n",
            "INFO:tensorflow:Step 8100 per-step time 0.329s\n",
            "I0627 19:50:21.550983 140309799094144 model_lib_v2.py:707] Step 8100 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041102216,\n",
            " 'Loss/localization_loss': 0.013617136,\n",
            " 'Loss/regularization_loss': 0.105084665,\n",
            " 'Loss/total_loss': 0.15980402,\n",
            " 'learning_rate': 0.07592674}\n",
            "I0627 19:50:21.551303 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.041102216,\n",
            " 'Loss/localization_loss': 0.013617136,\n",
            " 'Loss/regularization_loss': 0.105084665,\n",
            " 'Loss/total_loss': 0.15980402,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.325s\n",
            "I0627 19:50:54.073037 140309799094144 model_lib_v2.py:707] Step 8200 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06864944,\n",
            " 'Loss/localization_loss': 0.025877481,\n",
            " 'Loss/regularization_loss': 0.104758635,\n",
            " 'Loss/total_loss': 0.19928557,\n",
            " 'learning_rate': 0.075813256}\n",
            "I0627 19:50:54.073354 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06864944,\n",
            " 'Loss/localization_loss': 0.025877481,\n",
            " 'Loss/regularization_loss': 0.104758635,\n",
            " 'Loss/total_loss': 0.19928557,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.323s\n",
            "I0627 19:51:26.379538 140309799094144 model_lib_v2.py:707] Step 8300 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06537056,\n",
            " 'Loss/localization_loss': 0.0117976535,\n",
            " 'Loss/regularization_loss': 0.10425925,\n",
            " 'Loss/total_loss': 0.18142746,\n",
            " 'learning_rate': 0.07569829}\n",
            "I0627 19:51:26.379851 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06537056,\n",
            " 'Loss/localization_loss': 0.0117976535,\n",
            " 'Loss/regularization_loss': 0.10425925,\n",
            " 'Loss/total_loss': 0.18142746,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.321s\n",
            "I0627 19:51:58.524493 140309799094144 model_lib_v2.py:707] Step 8400 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07021276,\n",
            " 'Loss/localization_loss': 0.016319105,\n",
            " 'Loss/regularization_loss': 0.10379939,\n",
            " 'Loss/total_loss': 0.19033125,\n",
            " 'learning_rate': 0.07558186}\n",
            "I0627 19:51:58.524825 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07021276,\n",
            " 'Loss/localization_loss': 0.016319105,\n",
            " 'Loss/regularization_loss': 0.10379939,\n",
            " 'Loss/total_loss': 0.19033125,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.322s\n",
            "I0627 19:52:30.725982 140309799094144 model_lib_v2.py:707] Step 8500 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.075055495,\n",
            " 'Loss/localization_loss': 0.021673514,\n",
            " 'Loss/regularization_loss': 0.10342445,\n",
            " 'Loss/total_loss': 0.20015347,\n",
            " 'learning_rate': 0.07546397}\n",
            "I0627 19:52:30.726287 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.075055495,\n",
            " 'Loss/localization_loss': 0.021673514,\n",
            " 'Loss/regularization_loss': 0.10342445,\n",
            " 'Loss/total_loss': 0.20015347,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.320s\n",
            "I0627 19:53:02.722942 140309799094144 model_lib_v2.py:707] Step 8600 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08021713,\n",
            " 'Loss/localization_loss': 0.02162085,\n",
            " 'Loss/regularization_loss': 0.10300782,\n",
            " 'Loss/total_loss': 0.2048458,\n",
            " 'learning_rate': 0.075344615}\n",
            "I0627 19:53:02.723242 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.08021713,\n",
            " 'Loss/localization_loss': 0.02162085,\n",
            " 'Loss/regularization_loss': 0.10300782,\n",
            " 'Loss/total_loss': 0.2048458,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.321s\n",
            "I0627 19:53:34.799584 140309799094144 model_lib_v2.py:707] Step 8700 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04459618,\n",
            " 'Loss/localization_loss': 0.015141467,\n",
            " 'Loss/regularization_loss': 0.10255362,\n",
            " 'Loss/total_loss': 0.16229126,\n",
            " 'learning_rate': 0.07522382}\n",
            "I0627 19:53:34.799881 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.04459618,\n",
            " 'Loss/localization_loss': 0.015141467,\n",
            " 'Loss/regularization_loss': 0.10255362,\n",
            " 'Loss/total_loss': 0.16229126,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.322s\n",
            "I0627 19:54:07.027890 140309799094144 model_lib_v2.py:707] Step 8800 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055068757,\n",
            " 'Loss/localization_loss': 0.016319048,\n",
            " 'Loss/regularization_loss': 0.10205892,\n",
            " 'Loss/total_loss': 0.17344671,\n",
            " 'learning_rate': 0.07510157}\n",
            "I0627 19:54:07.028220 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.055068757,\n",
            " 'Loss/localization_loss': 0.016319048,\n",
            " 'Loss/regularization_loss': 0.10205892,\n",
            " 'Loss/total_loss': 0.17344671,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.321s\n",
            "I0627 19:54:39.138338 140309799094144 model_lib_v2.py:707] Step 8900 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05770036,\n",
            " 'Loss/localization_loss': 0.018629378,\n",
            " 'Loss/regularization_loss': 0.10163735,\n",
            " 'Loss/total_loss': 0.17796709,\n",
            " 'learning_rate': 0.074977875}\n",
            "I0627 19:54:39.138637 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05770036,\n",
            " 'Loss/localization_loss': 0.018629378,\n",
            " 'Loss/regularization_loss': 0.10163735,\n",
            " 'Loss/total_loss': 0.17796709,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.322s\n",
            "I0627 19:55:11.322186 140309799094144 model_lib_v2.py:707] Step 9000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05496408,\n",
            " 'Loss/localization_loss': 0.011142534,\n",
            " 'Loss/regularization_loss': 0.10121732,\n",
            " 'Loss/total_loss': 0.16732395,\n",
            " 'learning_rate': 0.07485275}\n",
            "I0627 19:55:11.322529 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05496408,\n",
            " 'Loss/localization_loss': 0.011142534,\n",
            " 'Loss/regularization_loss': 0.10121732,\n",
            " 'Loss/total_loss': 0.16732395,\n",
            " 'learning_rate': 0.07485275}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.325s\n",
            "I0627 19:55:43.815990 140309799094144 model_lib_v2.py:707] Step 9100 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07505336,\n",
            " 'Loss/localization_loss': 0.017377743,\n",
            " 'Loss/regularization_loss': 0.1007679,\n",
            " 'Loss/total_loss': 0.19319901,\n",
            " 'learning_rate': 0.07472619}\n",
            "I0627 19:55:43.816304 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07505336,\n",
            " 'Loss/localization_loss': 0.017377743,\n",
            " 'Loss/regularization_loss': 0.1007679,\n",
            " 'Loss/total_loss': 0.19319901,\n",
            " 'learning_rate': 0.07472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.319s\n",
            "I0627 19:56:15.710151 140309799094144 model_lib_v2.py:707] Step 9200 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07029218,\n",
            " 'Loss/localization_loss': 0.019794416,\n",
            " 'Loss/regularization_loss': 0.100333065,\n",
            " 'Loss/total_loss': 0.19041966,\n",
            " 'learning_rate': 0.07459819}\n",
            "I0627 19:56:15.710507 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07029218,\n",
            " 'Loss/localization_loss': 0.019794416,\n",
            " 'Loss/regularization_loss': 0.100333065,\n",
            " 'Loss/total_loss': 0.19041966,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.322s\n",
            "I0627 19:56:47.954154 140309799094144 model_lib_v2.py:707] Step 9300 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.084907405,\n",
            " 'Loss/localization_loss': 0.019867279,\n",
            " 'Loss/regularization_loss': 0.09991535,\n",
            " 'Loss/total_loss': 0.20469004,\n",
            " 'learning_rate': 0.074468784}\n",
            "I0627 19:56:47.954469 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.084907405,\n",
            " 'Loss/localization_loss': 0.019867279,\n",
            " 'Loss/regularization_loss': 0.09991535,\n",
            " 'Loss/total_loss': 0.20469004,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.320s\n",
            "I0627 19:57:19.997451 140309799094144 model_lib_v2.py:707] Step 9400 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07090421,\n",
            " 'Loss/localization_loss': 0.019738173,\n",
            " 'Loss/regularization_loss': 0.099465355,\n",
            " 'Loss/total_loss': 0.19010773,\n",
            " 'learning_rate': 0.074337944}\n",
            "I0627 19:57:19.997748 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07090421,\n",
            " 'Loss/localization_loss': 0.019738173,\n",
            " 'Loss/regularization_loss': 0.099465355,\n",
            " 'Loss/total_loss': 0.19010773,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.322s\n",
            "I0627 19:57:52.190161 140309799094144 model_lib_v2.py:707] Step 9500 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05582842,\n",
            " 'Loss/localization_loss': 0.012262054,\n",
            " 'Loss/regularization_loss': 0.09897844,\n",
            " 'Loss/total_loss': 0.1670689,\n",
            " 'learning_rate': 0.074205704}\n",
            "I0627 19:57:52.190523 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05582842,\n",
            " 'Loss/localization_loss': 0.012262054,\n",
            " 'Loss/regularization_loss': 0.09897844,\n",
            " 'Loss/total_loss': 0.1670689,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.324s\n",
            "I0627 19:58:24.562776 140309799094144 model_lib_v2.py:707] Step 9600 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0714065,\n",
            " 'Loss/localization_loss': 0.009828188,\n",
            " 'Loss/regularization_loss': 0.09859413,\n",
            " 'Loss/total_loss': 0.17982882,\n",
            " 'learning_rate': 0.07407206}\n",
            "I0627 19:58:24.563074 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.0714065,\n",
            " 'Loss/localization_loss': 0.009828188,\n",
            " 'Loss/regularization_loss': 0.09859413,\n",
            " 'Loss/total_loss': 0.17982882,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.322s\n",
            "I0627 19:58:56.713203 140309799094144 model_lib_v2.py:707] Step 9700 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039584987,\n",
            " 'Loss/localization_loss': 0.0085382,\n",
            " 'Loss/regularization_loss': 0.09820897,\n",
            " 'Loss/total_loss': 0.14633216,\n",
            " 'learning_rate': 0.073937014}\n",
            "I0627 19:58:56.713516 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.039584987,\n",
            " 'Loss/localization_loss': 0.0085382,\n",
            " 'Loss/regularization_loss': 0.09820897,\n",
            " 'Loss/total_loss': 0.14633216,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.323s\n",
            "I0627 19:59:28.968273 140309799094144 model_lib_v2.py:707] Step 9800 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09589455,\n",
            " 'Loss/localization_loss': 0.016547833,\n",
            " 'Loss/regularization_loss': 0.09775526,\n",
            " 'Loss/total_loss': 0.21019766,\n",
            " 'learning_rate': 0.07380057}\n",
            "I0627 19:59:28.968586 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.09589455,\n",
            " 'Loss/localization_loss': 0.016547833,\n",
            " 'Loss/regularization_loss': 0.09775526,\n",
            " 'Loss/total_loss': 0.21019766,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.321s\n",
            "I0627 20:00:01.068388 140309799094144 model_lib_v2.py:707] Step 9900 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044321127,\n",
            " 'Loss/localization_loss': 0.012641867,\n",
            " 'Loss/regularization_loss': 0.09729082,\n",
            " 'Loss/total_loss': 0.15425381,\n",
            " 'learning_rate': 0.073662736}\n",
            "I0627 20:00:01.068712 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.044321127,\n",
            " 'Loss/localization_loss': 0.012641867,\n",
            " 'Loss/regularization_loss': 0.09729082,\n",
            " 'Loss/total_loss': 0.15425381,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.322s\n",
            "I0627 20:00:33.258621 140309799094144 model_lib_v2.py:707] Step 10000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054272763,\n",
            " 'Loss/localization_loss': 0.020190168,\n",
            " 'Loss/regularization_loss': 0.09687486,\n",
            " 'Loss/total_loss': 0.1713378,\n",
            " 'learning_rate': 0.07352352}\n",
            "I0627 20:00:33.258932 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.054272763,\n",
            " 'Loss/localization_loss': 0.020190168,\n",
            " 'Loss/regularization_loss': 0.09687486,\n",
            " 'Loss/total_loss': 0.1713378,\n",
            " 'learning_rate': 0.07352352}\n",
            "INFO:tensorflow:Step 10100 per-step time 0.329s\n",
            "I0627 20:01:06.157794 140309799094144 model_lib_v2.py:707] Step 10100 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036403865,\n",
            " 'Loss/localization_loss': 0.007093944,\n",
            " 'Loss/regularization_loss': 0.09644574,\n",
            " 'Loss/total_loss': 0.13994354,\n",
            " 'learning_rate': 0.07338293}\n",
            "I0627 20:01:06.158107 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.036403865,\n",
            " 'Loss/localization_loss': 0.007093944,\n",
            " 'Loss/regularization_loss': 0.09644574,\n",
            " 'Loss/total_loss': 0.13994354,\n",
            " 'learning_rate': 0.07338293}\n",
            "INFO:tensorflow:Step 10200 per-step time 0.322s\n",
            "I0627 20:01:38.339756 140309799094144 model_lib_v2.py:707] Step 10200 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039602607,\n",
            " 'Loss/localization_loss': 0.009127921,\n",
            " 'Loss/regularization_loss': 0.095976785,\n",
            " 'Loss/total_loss': 0.14470732,\n",
            " 'learning_rate': 0.073240966}\n",
            "I0627 20:01:38.340072 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.039602607,\n",
            " 'Loss/localization_loss': 0.009127921,\n",
            " 'Loss/regularization_loss': 0.095976785,\n",
            " 'Loss/total_loss': 0.14470732,\n",
            " 'learning_rate': 0.073240966}\n",
            "INFO:tensorflow:Step 10300 per-step time 0.322s\n",
            "I0627 20:02:10.588140 140309799094144 model_lib_v2.py:707] Step 10300 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07432375,\n",
            " 'Loss/localization_loss': 0.025585452,\n",
            " 'Loss/regularization_loss': 0.09553944,\n",
            " 'Loss/total_loss': 0.19544864,\n",
            " 'learning_rate': 0.07309763}\n",
            "I0627 20:02:10.588493 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07432375,\n",
            " 'Loss/localization_loss': 0.025585452,\n",
            " 'Loss/regularization_loss': 0.09553944,\n",
            " 'Loss/total_loss': 0.19544864,\n",
            " 'learning_rate': 0.07309763}\n",
            "INFO:tensorflow:Step 10400 per-step time 0.319s\n",
            "I0627 20:02:42.516355 140309799094144 model_lib_v2.py:707] Step 10400 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07893676,\n",
            " 'Loss/localization_loss': 0.015471966,\n",
            " 'Loss/regularization_loss': 0.095153295,\n",
            " 'Loss/total_loss': 0.18956202,\n",
            " 'learning_rate': 0.07295293}\n",
            "I0627 20:02:42.516648 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07893676,\n",
            " 'Loss/localization_loss': 0.015471966,\n",
            " 'Loss/regularization_loss': 0.095153295,\n",
            " 'Loss/total_loss': 0.18956202,\n",
            " 'learning_rate': 0.07295293}\n",
            "INFO:tensorflow:Step 10500 per-step time 0.321s\n",
            "I0627 20:03:14.661489 140309799094144 model_lib_v2.py:707] Step 10500 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05497246,\n",
            " 'Loss/localization_loss': 0.0144815035,\n",
            " 'Loss/regularization_loss': 0.09478154,\n",
            " 'Loss/total_loss': 0.1642355,\n",
            " 'learning_rate': 0.07280689}\n",
            "I0627 20:03:14.661783 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05497246,\n",
            " 'Loss/localization_loss': 0.0144815035,\n",
            " 'Loss/regularization_loss': 0.09478154,\n",
            " 'Loss/total_loss': 0.1642355,\n",
            " 'learning_rate': 0.07280689}\n",
            "INFO:tensorflow:Step 10600 per-step time 0.326s\n",
            "I0627 20:03:47.220285 140309799094144 model_lib_v2.py:707] Step 10600 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037144255,\n",
            " 'Loss/localization_loss': 0.009297603,\n",
            " 'Loss/regularization_loss': 0.09436348,\n",
            " 'Loss/total_loss': 0.14080533,\n",
            " 'learning_rate': 0.07265949}\n",
            "I0627 20:03:47.220633 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.037144255,\n",
            " 'Loss/localization_loss': 0.009297603,\n",
            " 'Loss/regularization_loss': 0.09436348,\n",
            " 'Loss/total_loss': 0.14080533,\n",
            " 'learning_rate': 0.07265949}\n",
            "INFO:tensorflow:Step 10700 per-step time 0.324s\n",
            "I0627 20:04:19.600993 140309799094144 model_lib_v2.py:707] Step 10700 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07984639,\n",
            " 'Loss/localization_loss': 0.029471004,\n",
            " 'Loss/regularization_loss': 0.09398735,\n",
            " 'Loss/total_loss': 0.20330474,\n",
            " 'learning_rate': 0.07251076}\n",
            "I0627 20:04:19.601322 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07984639,\n",
            " 'Loss/localization_loss': 0.029471004,\n",
            " 'Loss/regularization_loss': 0.09398735,\n",
            " 'Loss/total_loss': 0.20330474,\n",
            " 'learning_rate': 0.07251076}\n",
            "INFO:tensorflow:Step 10800 per-step time 0.322s\n",
            "I0627 20:04:51.766338 140309799094144 model_lib_v2.py:707] Step 10800 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06354368,\n",
            " 'Loss/localization_loss': 0.015034349,\n",
            " 'Loss/regularization_loss': 0.09359388,\n",
            " 'Loss/total_loss': 0.1721719,\n",
            " 'learning_rate': 0.07236068}\n",
            "I0627 20:04:51.766648 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06354368,\n",
            " 'Loss/localization_loss': 0.015034349,\n",
            " 'Loss/regularization_loss': 0.09359388,\n",
            " 'Loss/total_loss': 0.1721719,\n",
            " 'learning_rate': 0.07236068}\n",
            "INFO:tensorflow:Step 10900 per-step time 0.326s\n",
            "I0627 20:05:24.368005 140309799094144 model_lib_v2.py:707] Step 10900 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049486898,\n",
            " 'Loss/localization_loss': 0.016230524,\n",
            " 'Loss/regularization_loss': 0.0931726,\n",
            " 'Loss/total_loss': 0.15889002,\n",
            " 'learning_rate': 0.07220927}\n",
            "I0627 20:05:24.368301 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.049486898,\n",
            " 'Loss/localization_loss': 0.016230524,\n",
            " 'Loss/regularization_loss': 0.0931726,\n",
            " 'Loss/total_loss': 0.15889002,\n",
            " 'learning_rate': 0.07220927}\n",
            "INFO:tensorflow:Step 11000 per-step time 0.323s\n",
            "I0627 20:05:56.699754 140309799094144 model_lib_v2.py:707] Step 11000 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061224334,\n",
            " 'Loss/localization_loss': 0.018302867,\n",
            " 'Loss/regularization_loss': 0.09277895,\n",
            " 'Loss/total_loss': 0.17230615,\n",
            " 'learning_rate': 0.07205655}\n",
            "I0627 20:05:56.700092 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.061224334,\n",
            " 'Loss/localization_loss': 0.018302867,\n",
            " 'Loss/regularization_loss': 0.09277895,\n",
            " 'Loss/total_loss': 0.17230615,\n",
            " 'learning_rate': 0.07205655}\n",
            "INFO:tensorflow:Step 11100 per-step time 0.326s\n",
            "I0627 20:06:29.336772 140309799094144 model_lib_v2.py:707] Step 11100 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037751693,\n",
            " 'Loss/localization_loss': 0.009954796,\n",
            " 'Loss/regularization_loss': 0.09239586,\n",
            " 'Loss/total_loss': 0.14010234,\n",
            " 'learning_rate': 0.07190249}\n",
            "I0627 20:06:29.337111 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.037751693,\n",
            " 'Loss/localization_loss': 0.009954796,\n",
            " 'Loss/regularization_loss': 0.09239586,\n",
            " 'Loss/total_loss': 0.14010234,\n",
            " 'learning_rate': 0.07190249}\n",
            "INFO:tensorflow:Step 11200 per-step time 0.322s\n",
            "I0627 20:07:01.577687 140309799094144 model_lib_v2.py:707] Step 11200 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03446264,\n",
            " 'Loss/localization_loss': 0.0089479275,\n",
            " 'Loss/regularization_loss': 0.09197351,\n",
            " 'Loss/total_loss': 0.13538408,\n",
            " 'learning_rate': 0.07174714}\n",
            "I0627 20:07:01.577980 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.03446264,\n",
            " 'Loss/localization_loss': 0.0089479275,\n",
            " 'Loss/regularization_loss': 0.09197351,\n",
            " 'Loss/total_loss': 0.13538408,\n",
            " 'learning_rate': 0.07174714}\n",
            "INFO:tensorflow:Step 11300 per-step time 0.322s\n",
            "I0627 20:07:33.824185 140309799094144 model_lib_v2.py:707] Step 11300 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04751902,\n",
            " 'Loss/localization_loss': 0.01436401,\n",
            " 'Loss/regularization_loss': 0.09162716,\n",
            " 'Loss/total_loss': 0.15351018,\n",
            " 'learning_rate': 0.071590476}\n",
            "I0627 20:07:33.824503 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.04751902,\n",
            " 'Loss/localization_loss': 0.01436401,\n",
            " 'Loss/regularization_loss': 0.09162716,\n",
            " 'Loss/total_loss': 0.15351018,\n",
            " 'learning_rate': 0.071590476}\n",
            "INFO:tensorflow:Step 11400 per-step time 0.318s\n",
            "I0627 20:08:05.638589 140309799094144 model_lib_v2.py:707] Step 11400 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041585337,\n",
            " 'Loss/localization_loss': 0.007596454,\n",
            " 'Loss/regularization_loss': 0.09133143,\n",
            " 'Loss/total_loss': 0.14051323,\n",
            " 'learning_rate': 0.071432516}\n",
            "I0627 20:08:05.638930 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.041585337,\n",
            " 'Loss/localization_loss': 0.007596454,\n",
            " 'Loss/regularization_loss': 0.09133143,\n",
            " 'Loss/total_loss': 0.14051323,\n",
            " 'learning_rate': 0.071432516}\n",
            "INFO:tensorflow:Step 11500 per-step time 0.321s\n",
            "I0627 20:08:37.743613 140309799094144 model_lib_v2.py:707] Step 11500 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043620672,\n",
            " 'Loss/localization_loss': 0.00880394,\n",
            " 'Loss/regularization_loss': 0.09094381,\n",
            " 'Loss/total_loss': 0.14336842,\n",
            " 'learning_rate': 0.07127326}\n",
            "I0627 20:08:37.743908 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.043620672,\n",
            " 'Loss/localization_loss': 0.00880394,\n",
            " 'Loss/regularization_loss': 0.09094381,\n",
            " 'Loss/total_loss': 0.14336842,\n",
            " 'learning_rate': 0.07127326}\n",
            "INFO:tensorflow:Step 11600 per-step time 0.322s\n",
            "I0627 20:09:09.992717 140309799094144 model_lib_v2.py:707] Step 11600 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03825481,\n",
            " 'Loss/localization_loss': 0.008828025,\n",
            " 'Loss/regularization_loss': 0.090558305,\n",
            " 'Loss/total_loss': 0.13764113,\n",
            " 'learning_rate': 0.071112715}\n",
            "I0627 20:09:09.993023 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.03825481,\n",
            " 'Loss/localization_loss': 0.008828025,\n",
            " 'Loss/regularization_loss': 0.090558305,\n",
            " 'Loss/total_loss': 0.13764113,\n",
            " 'learning_rate': 0.071112715}\n",
            "INFO:tensorflow:Step 11700 per-step time 0.322s\n",
            "I0627 20:09:42.186104 140309799094144 model_lib_v2.py:707] Step 11700 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050166614,\n",
            " 'Loss/localization_loss': 0.020453723,\n",
            " 'Loss/regularization_loss': 0.09015795,\n",
            " 'Loss/total_loss': 0.16077828,\n",
            " 'learning_rate': 0.070950896}\n",
            "I0627 20:09:42.186426 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.050166614,\n",
            " 'Loss/localization_loss': 0.020453723,\n",
            " 'Loss/regularization_loss': 0.09015795,\n",
            " 'Loss/total_loss': 0.16077828,\n",
            " 'learning_rate': 0.070950896}\n",
            "INFO:tensorflow:Step 11800 per-step time 0.321s\n",
            "I0627 20:10:14.246320 140309799094144 model_lib_v2.py:707] Step 11800 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04828681,\n",
            " 'Loss/localization_loss': 0.009359709,\n",
            " 'Loss/regularization_loss': 0.089811474,\n",
            " 'Loss/total_loss': 0.14745799,\n",
            " 'learning_rate': 0.07078781}\n",
            "I0627 20:10:14.246644 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.04828681,\n",
            " 'Loss/localization_loss': 0.009359709,\n",
            " 'Loss/regularization_loss': 0.089811474,\n",
            " 'Loss/total_loss': 0.14745799,\n",
            " 'learning_rate': 0.07078781}\n",
            "INFO:tensorflow:Step 11900 per-step time 0.324s\n",
            "I0627 20:10:46.636095 140309799094144 model_lib_v2.py:707] Step 11900 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06166309,\n",
            " 'Loss/localization_loss': 0.020009587,\n",
            " 'Loss/regularization_loss': 0.08946004,\n",
            " 'Loss/total_loss': 0.17113271,\n",
            " 'learning_rate': 0.07062345}\n",
            "I0627 20:10:46.636408 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06166309,\n",
            " 'Loss/localization_loss': 0.020009587,\n",
            " 'Loss/regularization_loss': 0.08946004,\n",
            " 'Loss/total_loss': 0.17113271,\n",
            " 'learning_rate': 0.07062345}\n",
            "INFO:tensorflow:Step 12000 per-step time 0.323s\n",
            "I0627 20:11:18.901767 140309799094144 model_lib_v2.py:707] Step 12000 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.107985094,\n",
            " 'Loss/localization_loss': 0.019273888,\n",
            " 'Loss/regularization_loss': 0.08912664,\n",
            " 'Loss/total_loss': 0.21638563,\n",
            " 'learning_rate': 0.07045784}\n",
            "I0627 20:11:18.902057 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.107985094,\n",
            " 'Loss/localization_loss': 0.019273888,\n",
            " 'Loss/regularization_loss': 0.08912664,\n",
            " 'Loss/total_loss': 0.21638563,\n",
            " 'learning_rate': 0.07045784}\n",
            "INFO:tensorflow:Step 12100 per-step time 0.327s\n",
            "I0627 20:11:51.589892 140309799094144 model_lib_v2.py:707] Step 12100 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09836221,\n",
            " 'Loss/localization_loss': 0.029733157,\n",
            " 'Loss/regularization_loss': 0.08873306,\n",
            " 'Loss/total_loss': 0.21682842,\n",
            " 'learning_rate': 0.07029097}\n",
            "I0627 20:11:51.590232 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.09836221,\n",
            " 'Loss/localization_loss': 0.029733157,\n",
            " 'Loss/regularization_loss': 0.08873306,\n",
            " 'Loss/total_loss': 0.21682842,\n",
            " 'learning_rate': 0.07029097}\n",
            "INFO:tensorflow:Step 12200 per-step time 0.324s\n",
            "I0627 20:12:23.993379 140309799094144 model_lib_v2.py:707] Step 12200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06259182,\n",
            " 'Loss/localization_loss': 0.023540845,\n",
            " 'Loss/regularization_loss': 0.08839028,\n",
            " 'Loss/total_loss': 0.17452295,\n",
            " 'learning_rate': 0.07012285}\n",
            "I0627 20:12:23.993674 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06259182,\n",
            " 'Loss/localization_loss': 0.023540845,\n",
            " 'Loss/regularization_loss': 0.08839028,\n",
            " 'Loss/total_loss': 0.17452295,\n",
            " 'learning_rate': 0.07012285}\n",
            "INFO:tensorflow:Step 12300 per-step time 0.322s\n",
            "I0627 20:12:56.146863 140309799094144 model_lib_v2.py:707] Step 12300 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05571957,\n",
            " 'Loss/localization_loss': 0.022385653,\n",
            " 'Loss/regularization_loss': 0.088054076,\n",
            " 'Loss/total_loss': 0.1661593,\n",
            " 'learning_rate': 0.06995351}\n",
            "I0627 20:12:56.147182 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05571957,\n",
            " 'Loss/localization_loss': 0.022385653,\n",
            " 'Loss/regularization_loss': 0.088054076,\n",
            " 'Loss/total_loss': 0.1661593,\n",
            " 'learning_rate': 0.06995351}\n",
            "INFO:tensorflow:Step 12400 per-step time 0.322s\n",
            "I0627 20:13:28.319282 140309799094144 model_lib_v2.py:707] Step 12400 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06795889,\n",
            " 'Loss/localization_loss': 0.051622104,\n",
            " 'Loss/regularization_loss': 0.08795182,\n",
            " 'Loss/total_loss': 0.20753282,\n",
            " 'learning_rate': 0.06978292}\n",
            "I0627 20:13:28.319596 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06795889,\n",
            " 'Loss/localization_loss': 0.051622104,\n",
            " 'Loss/regularization_loss': 0.08795182,\n",
            " 'Loss/total_loss': 0.20753282,\n",
            " 'learning_rate': 0.06978292}\n",
            "INFO:tensorflow:Step 12500 per-step time 0.324s\n",
            "I0627 20:14:00.698015 140309799094144 model_lib_v2.py:707] Step 12500 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059660457,\n",
            " 'Loss/localization_loss': 0.020232178,\n",
            " 'Loss/regularization_loss': 0.08765642,\n",
            " 'Loss/total_loss': 0.16754906,\n",
            " 'learning_rate': 0.06961112}\n",
            "I0627 20:14:00.698358 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.059660457,\n",
            " 'Loss/localization_loss': 0.020232178,\n",
            " 'Loss/regularization_loss': 0.08765642,\n",
            " 'Loss/total_loss': 0.16754906,\n",
            " 'learning_rate': 0.06961112}\n",
            "INFO:tensorflow:Step 12600 per-step time 0.323s\n",
            "I0627 20:14:33.039488 140309799094144 model_lib_v2.py:707] Step 12600 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08468452,\n",
            " 'Loss/localization_loss': 0.008965988,\n",
            " 'Loss/regularization_loss': 0.087365404,\n",
            " 'Loss/total_loss': 0.18101591,\n",
            " 'learning_rate': 0.06943809}\n",
            "I0627 20:14:33.039816 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.08468452,\n",
            " 'Loss/localization_loss': 0.008965988,\n",
            " 'Loss/regularization_loss': 0.087365404,\n",
            " 'Loss/total_loss': 0.18101591,\n",
            " 'learning_rate': 0.06943809}\n",
            "INFO:tensorflow:Step 12700 per-step time 0.324s\n",
            "I0627 20:15:05.464516 140309799094144 model_lib_v2.py:707] Step 12700 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048614766,\n",
            " 'Loss/localization_loss': 0.010479005,\n",
            " 'Loss/regularization_loss': 0.087012306,\n",
            " 'Loss/total_loss': 0.14610608,\n",
            " 'learning_rate': 0.06926386}\n",
            "I0627 20:15:05.464815 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.048614766,\n",
            " 'Loss/localization_loss': 0.010479005,\n",
            " 'Loss/regularization_loss': 0.087012306,\n",
            " 'Loss/total_loss': 0.14610608,\n",
            " 'learning_rate': 0.06926386}\n",
            "INFO:tensorflow:Step 12800 per-step time 0.327s\n",
            "I0627 20:15:38.172118 140309799094144 model_lib_v2.py:707] Step 12800 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0564222,\n",
            " 'Loss/localization_loss': 0.010967142,\n",
            " 'Loss/regularization_loss': 0.086625,\n",
            " 'Loss/total_loss': 0.15401435,\n",
            " 'learning_rate': 0.06908842}\n",
            "I0627 20:15:38.172439 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.0564222,\n",
            " 'Loss/localization_loss': 0.010967142,\n",
            " 'Loss/regularization_loss': 0.086625,\n",
            " 'Loss/total_loss': 0.15401435,\n",
            " 'learning_rate': 0.06908842}\n",
            "INFO:tensorflow:Step 12900 per-step time 0.325s\n",
            "I0627 20:16:10.663232 140309799094144 model_lib_v2.py:707] Step 12900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052131858,\n",
            " 'Loss/localization_loss': 0.016969405,\n",
            " 'Loss/regularization_loss': 0.08625412,\n",
            " 'Loss/total_loss': 0.15535538,\n",
            " 'learning_rate': 0.06891179}\n",
            "I0627 20:16:10.663570 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.052131858,\n",
            " 'Loss/localization_loss': 0.016969405,\n",
            " 'Loss/regularization_loss': 0.08625412,\n",
            " 'Loss/total_loss': 0.15535538,\n",
            " 'learning_rate': 0.06891179}\n",
            "INFO:tensorflow:Step 13000 per-step time 0.325s\n",
            "I0627 20:16:43.156246 140309799094144 model_lib_v2.py:707] Step 13000 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09409249,\n",
            " 'Loss/localization_loss': 0.012594269,\n",
            " 'Loss/regularization_loss': 0.08629793,\n",
            " 'Loss/total_loss': 0.19298469,\n",
            " 'learning_rate': 0.068733975}\n",
            "I0627 20:16:43.156558 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.09409249,\n",
            " 'Loss/localization_loss': 0.012594269,\n",
            " 'Loss/regularization_loss': 0.08629793,\n",
            " 'Loss/total_loss': 0.19298469,\n",
            " 'learning_rate': 0.068733975}\n",
            "INFO:tensorflow:Step 13100 per-step time 0.328s\n",
            "I0627 20:17:15.916290 140309799094144 model_lib_v2.py:707] Step 13100 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08961128,\n",
            " 'Loss/localization_loss': 0.03767519,\n",
            " 'Loss/regularization_loss': 0.08606612,\n",
            " 'Loss/total_loss': 0.21335259,\n",
            " 'learning_rate': 0.068554975}\n",
            "I0627 20:17:15.916670 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.08961128,\n",
            " 'Loss/localization_loss': 0.03767519,\n",
            " 'Loss/regularization_loss': 0.08606612,\n",
            " 'Loss/total_loss': 0.21335259,\n",
            " 'learning_rate': 0.068554975}\n",
            "INFO:tensorflow:Step 13200 per-step time 0.321s\n",
            "I0627 20:17:48.037739 140309799094144 model_lib_v2.py:707] Step 13200 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04548868,\n",
            " 'Loss/localization_loss': 0.009975819,\n",
            " 'Loss/regularization_loss': 0.08573853,\n",
            " 'Loss/total_loss': 0.14120303,\n",
            " 'learning_rate': 0.0683748}\n",
            "I0627 20:17:48.038051 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.04548868,\n",
            " 'Loss/localization_loss': 0.009975819,\n",
            " 'Loss/regularization_loss': 0.08573853,\n",
            " 'Loss/total_loss': 0.14120303,\n",
            " 'learning_rate': 0.0683748}\n",
            "INFO:tensorflow:Step 13300 per-step time 0.321s\n",
            "I0627 20:18:20.164228 140309799094144 model_lib_v2.py:707] Step 13300 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041466676,\n",
            " 'Loss/localization_loss': 0.0075257816,\n",
            " 'Loss/regularization_loss': 0.08539677,\n",
            " 'Loss/total_loss': 0.13438922,\n",
            " 'learning_rate': 0.06819345}\n",
            "I0627 20:18:20.164555 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.041466676,\n",
            " 'Loss/localization_loss': 0.0075257816,\n",
            " 'Loss/regularization_loss': 0.08539677,\n",
            " 'Loss/total_loss': 0.13438922,\n",
            " 'learning_rate': 0.06819345}\n",
            "INFO:tensorflow:Step 13400 per-step time 0.323s\n",
            "I0627 20:18:52.453853 140309799094144 model_lib_v2.py:707] Step 13400 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.083928205,\n",
            " 'Loss/localization_loss': 0.013032834,\n",
            " 'Loss/regularization_loss': 0.0850396,\n",
            " 'Loss/total_loss': 0.18200064,\n",
            " 'learning_rate': 0.06801095}\n",
            "I0627 20:18:52.454150 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.083928205,\n",
            " 'Loss/localization_loss': 0.013032834,\n",
            " 'Loss/regularization_loss': 0.0850396,\n",
            " 'Loss/total_loss': 0.18200064,\n",
            " 'learning_rate': 0.06801095}\n",
            "INFO:tensorflow:Step 13500 per-step time 0.326s\n",
            "I0627 20:19:25.091492 140309799094144 model_lib_v2.py:707] Step 13500 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03543484,\n",
            " 'Loss/localization_loss': 0.012731618,\n",
            " 'Loss/regularization_loss': 0.08471528,\n",
            " 'Loss/total_loss': 0.13288173,\n",
            " 'learning_rate': 0.0678273}\n",
            "I0627 20:19:25.091784 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.03543484,\n",
            " 'Loss/localization_loss': 0.012731618,\n",
            " 'Loss/regularization_loss': 0.08471528,\n",
            " 'Loss/total_loss': 0.13288173,\n",
            " 'learning_rate': 0.0678273}\n",
            "INFO:tensorflow:Step 13600 per-step time 0.325s\n",
            "I0627 20:19:57.583502 140309799094144 model_lib_v2.py:707] Step 13600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06647606,\n",
            " 'Loss/localization_loss': 0.015416799,\n",
            " 'Loss/regularization_loss': 0.08438764,\n",
            " 'Loss/total_loss': 0.16628051,\n",
            " 'learning_rate': 0.0676425}\n",
            "I0627 20:19:57.583823 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06647606,\n",
            " 'Loss/localization_loss': 0.015416799,\n",
            " 'Loss/regularization_loss': 0.08438764,\n",
            " 'Loss/total_loss': 0.16628051,\n",
            " 'learning_rate': 0.0676425}\n",
            "INFO:tensorflow:Step 13700 per-step time 0.323s\n",
            "I0627 20:20:29.902511 140309799094144 model_lib_v2.py:707] Step 13700 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07767446,\n",
            " 'Loss/localization_loss': 0.007663035,\n",
            " 'Loss/regularization_loss': 0.08407594,\n",
            " 'Loss/total_loss': 0.16941345,\n",
            " 'learning_rate': 0.06745657}\n",
            "I0627 20:20:29.902818 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07767446,\n",
            " 'Loss/localization_loss': 0.007663035,\n",
            " 'Loss/regularization_loss': 0.08407594,\n",
            " 'Loss/total_loss': 0.16941345,\n",
            " 'learning_rate': 0.06745657}\n",
            "INFO:tensorflow:Step 13800 per-step time 0.325s\n",
            "I0627 20:21:02.413492 140309799094144 model_lib_v2.py:707] Step 13800 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039892364,\n",
            " 'Loss/localization_loss': 0.009931651,\n",
            " 'Loss/regularization_loss': 0.083726615,\n",
            " 'Loss/total_loss': 0.13355063,\n",
            " 'learning_rate': 0.06726951}\n",
            "I0627 20:21:02.413778 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.039892364,\n",
            " 'Loss/localization_loss': 0.009931651,\n",
            " 'Loss/regularization_loss': 0.083726615,\n",
            " 'Loss/total_loss': 0.13355063,\n",
            " 'learning_rate': 0.06726951}\n",
            "INFO:tensorflow:Step 13900 per-step time 0.323s\n",
            "I0627 20:21:34.666208 140309799094144 model_lib_v2.py:707] Step 13900 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034561474,\n",
            " 'Loss/localization_loss': 0.009759943,\n",
            " 'Loss/regularization_loss': 0.08337487,\n",
            " 'Loss/total_loss': 0.12769629,\n",
            " 'learning_rate': 0.067081325}\n",
            "I0627 20:21:34.666556 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.034561474,\n",
            " 'Loss/localization_loss': 0.009759943,\n",
            " 'Loss/regularization_loss': 0.08337487,\n",
            " 'Loss/total_loss': 0.12769629,\n",
            " 'learning_rate': 0.067081325}\n",
            "INFO:tensorflow:Step 14000 per-step time 0.322s\n",
            "I0627 20:22:06.890842 140309799094144 model_lib_v2.py:707] Step 14000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074230924,\n",
            " 'Loss/localization_loss': 0.0147288535,\n",
            " 'Loss/regularization_loss': 0.08307179,\n",
            " 'Loss/total_loss': 0.17203157,\n",
            " 'learning_rate': 0.06689203}\n",
            "I0627 20:22:06.891168 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.074230924,\n",
            " 'Loss/localization_loss': 0.0147288535,\n",
            " 'Loss/regularization_loss': 0.08307179,\n",
            " 'Loss/total_loss': 0.17203157,\n",
            " 'learning_rate': 0.06689203}\n",
            "INFO:tensorflow:Step 14100 per-step time 0.331s\n",
            "I0627 20:22:40.011849 140309799094144 model_lib_v2.py:707] Step 14100 per-step time 0.331s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04281622,\n",
            " 'Loss/localization_loss': 0.013240053,\n",
            " 'Loss/regularization_loss': 0.082777224,\n",
            " 'Loss/total_loss': 0.1388335,\n",
            " 'learning_rate': 0.06670163}\n",
            "I0627 20:22:40.012147 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.04281622,\n",
            " 'Loss/localization_loss': 0.013240053,\n",
            " 'Loss/regularization_loss': 0.082777224,\n",
            " 'Loss/total_loss': 0.1388335,\n",
            " 'learning_rate': 0.06670163}\n",
            "INFO:tensorflow:Step 14200 per-step time 0.327s\n",
            "I0627 20:23:12.694657 140309799094144 model_lib_v2.py:707] Step 14200 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048063125,\n",
            " 'Loss/localization_loss': 0.009157107,\n",
            " 'Loss/regularization_loss': 0.08245623,\n",
            " 'Loss/total_loss': 0.13967647,\n",
            " 'learning_rate': 0.06651013}\n",
            "I0627 20:23:12.694993 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.048063125,\n",
            " 'Loss/localization_loss': 0.009157107,\n",
            " 'Loss/regularization_loss': 0.08245623,\n",
            " 'Loss/total_loss': 0.13967647,\n",
            " 'learning_rate': 0.06651013}\n",
            "INFO:tensorflow:Step 14300 per-step time 0.326s\n",
            "I0627 20:23:45.271147 140309799094144 model_lib_v2.py:707] Step 14300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07445421,\n",
            " 'Loss/localization_loss': 0.027317308,\n",
            " 'Loss/regularization_loss': 0.082145184,\n",
            " 'Loss/total_loss': 0.1839167,\n",
            " 'learning_rate': 0.06631755}\n",
            "I0627 20:23:45.271462 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.07445421,\n",
            " 'Loss/localization_loss': 0.027317308,\n",
            " 'Loss/regularization_loss': 0.082145184,\n",
            " 'Loss/total_loss': 0.1839167,\n",
            " 'learning_rate': 0.06631755}\n",
            "INFO:tensorflow:Step 14400 per-step time 0.325s\n",
            "I0627 20:24:17.787108 140309799094144 model_lib_v2.py:707] Step 14400 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05870889,\n",
            " 'Loss/localization_loss': 0.0115582915,\n",
            " 'Loss/regularization_loss': 0.08182362,\n",
            " 'Loss/total_loss': 0.1520908,\n",
            " 'learning_rate': 0.06612387}\n",
            "I0627 20:24:17.787425 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.05870889,\n",
            " 'Loss/localization_loss': 0.0115582915,\n",
            " 'Loss/regularization_loss': 0.08182362,\n",
            " 'Loss/total_loss': 0.1520908,\n",
            " 'learning_rate': 0.06612387}\n",
            "INFO:tensorflow:Step 14500 per-step time 0.326s\n",
            "I0627 20:24:50.373840 140309799094144 model_lib_v2.py:707] Step 14500 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046358097,\n",
            " 'Loss/localization_loss': 0.008768428,\n",
            " 'Loss/regularization_loss': 0.08149667,\n",
            " 'Loss/total_loss': 0.1366232,\n",
            " 'learning_rate': 0.06592914}\n",
            "I0627 20:24:50.374137 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.046358097,\n",
            " 'Loss/localization_loss': 0.008768428,\n",
            " 'Loss/regularization_loss': 0.08149667,\n",
            " 'Loss/total_loss': 0.1366232,\n",
            " 'learning_rate': 0.06592914}\n",
            "INFO:tensorflow:Step 14600 per-step time 0.321s\n",
            "I0627 20:25:22.442286 140309799094144 model_lib_v2.py:707] Step 14600 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06342343,\n",
            " 'Loss/localization_loss': 0.008373479,\n",
            " 'Loss/regularization_loss': 0.08117065,\n",
            " 'Loss/total_loss': 0.15296756,\n",
            " 'learning_rate': 0.06573333}\n",
            "I0627 20:25:22.442591 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06342343,\n",
            " 'Loss/localization_loss': 0.008373479,\n",
            " 'Loss/regularization_loss': 0.08117065,\n",
            " 'Loss/total_loss': 0.15296756,\n",
            " 'learning_rate': 0.06573333}\n",
            "INFO:tensorflow:Step 14700 per-step time 0.322s\n",
            "I0627 20:25:54.652491 140309799094144 model_lib_v2.py:707] Step 14700 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06778991,\n",
            " 'Loss/localization_loss': 0.017771827,\n",
            " 'Loss/regularization_loss': 0.08087537,\n",
            " 'Loss/total_loss': 0.1664371,\n",
            " 'learning_rate': 0.06553646}\n",
            "I0627 20:25:54.652816 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.06778991,\n",
            " 'Loss/localization_loss': 0.017771827,\n",
            " 'Loss/regularization_loss': 0.08087537,\n",
            " 'Loss/total_loss': 0.1664371,\n",
            " 'learning_rate': 0.06553646}\n",
            "INFO:tensorflow:Step 14800 per-step time 0.323s\n",
            "I0627 20:26:26.980417 140309799094144 model_lib_v2.py:707] Step 14800 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054151464,\n",
            " 'Loss/localization_loss': 0.011189734,\n",
            " 'Loss/regularization_loss': 0.08054922,\n",
            " 'Loss/total_loss': 0.14589041,\n",
            " 'learning_rate': 0.065338545}\n",
            "I0627 20:26:26.980705 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.054151464,\n",
            " 'Loss/localization_loss': 0.011189734,\n",
            " 'Loss/regularization_loss': 0.08054922,\n",
            " 'Loss/total_loss': 0.14589041,\n",
            " 'learning_rate': 0.065338545}\n",
            "INFO:tensorflow:Step 14900 per-step time 0.324s\n",
            "I0627 20:26:59.409237 140309799094144 model_lib_v2.py:707] Step 14900 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053919528,\n",
            " 'Loss/localization_loss': 0.008812947,\n",
            " 'Loss/regularization_loss': 0.080247425,\n",
            " 'Loss/total_loss': 0.14297989,\n",
            " 'learning_rate': 0.06513958}\n",
            "I0627 20:26:59.409544 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.053919528,\n",
            " 'Loss/localization_loss': 0.008812947,\n",
            " 'Loss/regularization_loss': 0.080247425,\n",
            " 'Loss/total_loss': 0.14297989,\n",
            " 'learning_rate': 0.06513958}\n",
            "INFO:tensorflow:Step 15000 per-step time 0.323s\n",
            "I0627 20:27:31.728443 140309799094144 model_lib_v2.py:707] Step 15000 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03458641,\n",
            " 'Loss/localization_loss': 0.007111299,\n",
            " 'Loss/regularization_loss': 0.07992829,\n",
            " 'Loss/total_loss': 0.121626,\n",
            " 'learning_rate': 0.064939596}\n",
            "I0627 20:27:31.728785 140309799094144 model_lib_v2.py:708] {'Loss/classification_loss': 0.03458641,\n",
            " 'Loss/localization_loss': 0.007111299,\n",
            " 'Loss/regularization_loss': 0.07992829,\n",
            " 'Loss/total_loss': 0.121626,\n",
            " 'learning_rate': 0.064939596}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "85aff75d-0f55-418d-8749-e8c836f7cadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_mobilenet --pipeline_config_path=Tensorflow/workspace/models/my_mobilenet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_mobilenet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "outputId": "39b51429-26a9-4438-8710-d8f55cdae840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0627 19:05:06.283538 139942201255808 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0627 19:05:06.283741 139942201255808 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0627 19:05:06.283829 139942201255808 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0627 19:05:06.283916 139942201255808 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0627 19:05:06.284029 139942201255808 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-06-27 19:05:07.093841: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0627 19:05:07.250828 139942201255808 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0627 19:05:07.251071 139942201255808 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0627 19:05:07.251167 139942201255808 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0627 19:05:07.251247 139942201255808 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0627 19:05:07.253017 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0627 19:05:07.271764 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0627 19:05:11.100110 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 19:05:12.172166 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_mobilenet\n",
            "I0627 19:05:14.552349 139942201255808 checkpoint_utils.py:136] Waiting for new checkpoint at Tensorflow/workspace/models/my_mobilenet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_mobilenet/ckpt-6\n",
            "I0627 19:05:14.553275 139942201255808 checkpoint_utils.py:145] Found new checkpoint at Tensorflow/workspace/models/my_mobilenet/ckpt-6\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0627 19:05:38.495527 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0627 19:05:38.504642 139942201255808 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0627 19:05:38.620913 139942201255808 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Performing evaluation on 90 images.\n",
            "I0627 19:05:55.729709 139942201255808 coco_evaluation.py:293] Performing evaluation on 90 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0627 19:05:55.730615 139942201255808 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0627 19:05:55.735398 139942201255808 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.844\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
            "INFO:tensorflow:Eval metrics at step 5000\n",
            "I0627 19:05:56.399830 139942201255808 model_lib_v2.py:1015] Eval metrics at step 5000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.555282\n",
            "I0627 19:05:56.402926 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.555282\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.670982\n",
            "I0627 19:05:56.404348 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.670982\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.642733\n",
            "I0627 19:05:56.405687 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.642733\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.227190\n",
            "I0627 19:05:56.407018 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.227190\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.666235\n",
            "I0627 19:05:56.408271 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.666235\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.357013\n",
            "I0627 19:05:56.409517 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.357013\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.263208\n",
            "I0627 19:05:56.410752 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.263208\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.775502\n",
            "I0627 19:05:56.411961 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.775502\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.787777\n",
            "I0627 19:05:56.413152 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.787777\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.473969\n",
            "I0627 19:05:56.414437 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.473969\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.843936\n",
            "I0627 19:05:56.415684 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.843936\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.383333\n",
            "I0627 19:05:56.416972 139942201255808 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.383333\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.036713\n",
            "I0627 19:05:56.417918 139942201255808 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.036713\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.184387\n",
            "I0627 19:05:56.418925 139942201255808 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.184387\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.120710\n",
            "I0627 19:05:56.419934 139942201255808 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.120710\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.341810\n",
            "I0627 19:05:56.420908 139942201255808 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.341810\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n",
            "    time.sleep(time_to_next_eval)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-16')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'IMG_4330_wb10.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "4e9dcb8b-9732-4a09-b9a5-750deae6d856"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mais Training and Detection.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "12e2997e1db19daaf1ff42dd12ad38a26824f5495ce8e00160cc6cb4513d56f8"
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}